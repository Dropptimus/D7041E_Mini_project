{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import clustering_classification, test_classifier, write, save_metrics_to_dict, encode_categorical_features, import_dataset, agg_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter(log_dir=\"C:\\\\awilde\\\\britta\\\\LTU\\\\AppliedAI\\\\runs\")\n",
    "writer = SummaryWriter()\n",
    "metrics_dict={\n",
    "\"train_acc_dict\" : {},\n",
    "\"train_f1_dict\" : {},\n",
    "\"test_acc_dict\" : {},\n",
    "\"test_f1_dict\" : {},\n",
    "\"train_acc_avg\" : {},\n",
    "\"train_f1_avg\" : {},\n",
    "\"test_acc_avg\" : {},\n",
    "\"test_f1_avg\" : {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# Launch tensorboard\n",
    "# images=21 change this to how many datasets you use\n",
    "%tensorboard --logdir runs/ --port 6006 --samples_per_plugin images=22\n",
    "# If in use (Mac) use to find the process PID\n",
    "% lsof -i :6006\n",
    "# Kill the process with \n",
    "% kill -9 <PID>\n",
    "# Then launch using bash with first command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 41\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our chosen datasets\n",
    "TODO\n",
    "We have chosen the datasets based on the following criteria:\n",
    "- datasets where we do not need to do any special preprocessing so that it is easy to do in only one pipeline\n",
    "- rather small datasets to ensure we do not need high computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acute_inflamations': (184, 1), 'balance_scale': (12, 2), 'balloons': (13, 3), 'breast_cancer_wisconsin_diagnostic': (17, 4), 'car_evaluation': (19, 5), 'congress_voting_records': (105, 6), 'credit_approval': (27, 7), 'ecoli': (39, 8), 'fertility': (244, 9), 'habermans_survival': (43, 10), 'hayes_roth': (44, 11), 'heart_disease': (45, 12), 'ilpd': (225, 13), 'iris': (53, 14), 'lenses': (58, 15), 'mammographic_mass': (161, 16), 'mushroom': (73, 17), 'spect_heart': (95, 18), 'spectf_heart': (96, 19), 'statlog': (144, 20), 'wine_quality': (186, 21), 'zoo': (111, 22)}\n"
     ]
    }
   ],
   "source": [
    "# Dataset that seems useful\n",
    "dataset_id = {\n",
    "    \"iris\": 53, \n",
    "    \"heart_disease\": 45, \n",
    "    \"wine_quality\": 186, \n",
    "    \"breast_cancer_wisconsin_diagnostic\": 17, \n",
    "    \"car_evaluation\": 19, \n",
    "    \"spect_heart\" : 95, \n",
    "    \"spectf_heart\" : 96,\n",
    "    \"mushroom\": 73, \n",
    "    \"statlog\" : 144, \n",
    "    \"credit_approval\" : 27, \n",
    "    \"zoo\" : 111, \n",
    "    \"balance_scale\" : 12, \n",
    "    \"ilpd\" : 225, \n",
    "    \"acute_inflamations\" : 184, \n",
    "    \"ecoli\" : 39, \n",
    "    \"mammographic_mass\" : 161, \n",
    "    \"hayes_roth\" : 44, \n",
    "    \"habermans_survival\" : 43, \n",
    "    \"congress_voting_records\" : 105, \n",
    "    \"balloons\" : 13, \n",
    "    \"lenses\" : 58, \n",
    "    \"fertility\" : 244, \n",
    "}\n",
    "\n",
    "# sort alphabetically and adds id for logging\n",
    "data_set_sorted = {}\n",
    "for i, name in enumerate(sorted(dataset_id.keys())):\n",
    "    data_set_sorted[name] = (dataset_id[name], i+1)\n",
    "\n",
    "print(data_set_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preprocess datasets\n",
    "For the preprocessing we will do the following steps:\n",
    "1. Remove any missing values. In the article the following is written: \"Given that our classifiers are not oriented to data with missing features, the missing inputs are treated as zero, which should not bias the comparison results.\" We therefore also decided to just remove missing values and to more focus on the full pipeline instead of single datasets. Another way could have been interpolation.\n",
    "2. Encode categorical data into numerical data. This we have to do to use the classifiers later on.\n",
    "3. Remove certain columns if they are highly correlated to others. <span style=\"color: red;\">ALERT!</span>\n",
    "4. Split the data into a train and a test set. We will use a 80/20 split.\n",
    "5. Scale the data so that we have zero mean and standard deviation of one. This is done with the Standard scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "knn_params = [{'knn__n_neighbors': [3, 5, 7, 9],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__leaf_size': [15, 20]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "svm_params = [{'svm__C': [0.1, 1, 10, 100, 1000],  \n",
    "        'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "        'svm__kernel': ['rbf']} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/how-to-optimize-logistic-regression-performance/\n",
    "# and from here https://www.kaggle.com/code/enespolat/grid-search-with-logistic-regression\n",
    "log_reg_params = [\n",
    "    {'log_reg__penalty':['l1','l2'],\n",
    "    'log_reg__C' : np.logspace(-3,3,7),\n",
    "    'log_reg__max_iter'  : [100,1000,2500,5000]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "random_forest_params = [\n",
    "    {\"random_forest__n_estimators\": [100, 500],\n",
    "     \"random_forest__max_depth\" : [5, 10, 15]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/akshaysharma001/naive-bayes-with-hyperpameter-tuning#Hyperparameter-Tuning-to-improve-Accuracy\n",
    "gnb_params = [\n",
    "    {'gnb__var_smoothing': np.logspace(0,-9, num=10)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already use k-means++ and we set the no. clusters to no. of labels\n",
    "kmeans_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://letsdatascience.com/affinity-propagation-clustering/\n",
    "affinity_propagation_params = [\n",
    "    {\"damping\": [0.5, 0.7]}, \n",
    "    {\"preference\": [-50,-10,0,10,50]}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: acute_inflamations\n",
      "Dataset size: 120\n",
      "Labels in dataset: ['no' 'yes']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.9791666666666666, Test accuracy = 1.0\n",
      "gnb, Train f1-score = 0.9790823211875844, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8125, Test accuracy = 0.875\n",
      "kmeans, Train f1-score = 0.7982630272952854, Test f1-score = 0.8700189753320683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8431578947368421 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.8157894736842105, Test accuracy = 0.7916666666666666\n",
      "agglo, Train f1-score = 0.8026418988648091, Test f1-score = 0.7898550724637682\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balance_scale\n",
      "Dataset size: 625\n",
      "Labels in dataset: ['B' 'L' 'R']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.896\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.8588\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.984\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.984\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.001), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.88, Test accuracy = 0.888\n",
      "log_reg, Train f1-score = 0.8443403348237496, Test f1-score = 0.8512513368983957\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.918, Test accuracy = 0.896\n",
      "random_forest, Train f1-score = 0.8889352823364123, Test f1-score = 0.8591746031746031\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.904, Test accuracy = 0.912\n",
      "gnb, Train f1-score = 0.8673152628706567, Test f1-score = 0.874002916869227\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.656, Test accuracy = 0.696\n",
      "kmeans, Train f1-score = 0.6230455422443576, Test f1-score = 0.6600034492670307\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.5905 with params {'metric': 'l1', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.5125, Test accuracy = 0.712\n",
      "agglo, Train f1-score = 0.5324076981771424, Test f1-score = 0.7113041460257955\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.742, Test accuracy = 0.784\n",
      "affinity_propagation, Train f1-score = 0.7117482517482517, Test f1-score = 0.7516190476190477\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balloons\n",
      "Dataset size: 16\n",
      "Labels in dataset: ['F' 'T']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.25\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.2\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8333333333333334, Test accuracy = 0.5\n",
      "log_reg, Train f1-score = 0.8229166666666666, Test f1-score = 0.5\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.75\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.8333333333333334, Test accuracy = 0.25\n",
      "gnb, Train f1-score = 0.8229166666666666, Test f1-score = 0.2\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.5833333333333334, Test accuracy = 0.5\n",
      "kmeans, Train f1-score = 0.4298245614035088, Test f1-score = 0.3333333333333333\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6888888888888889 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': False}\n",
      "agglo, Train accuracy = 0.7777777777777778, Test accuracy = 0.5\n",
      "agglo, Train f1-score = 0.7777777777777778, Test f1-score = 0.5\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.5\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.3333333333333333\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: breast_cancer_wisconsin_diagnostic\n",
      "Dataset size: 569\n",
      "Labels in dataset: ['B' 'M']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9824175824175824, Test accuracy = 0.9736842105263158\n",
      "knn, Train f1-score = 0.9823512316027286, Test f1-score = 0.9734654095556351\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9868131868131869, Test accuracy = 0.9736842105263158\n",
      "svm, Train f1-score = 0.9867634237020464, Test f1-score = 0.9736164257756981\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.9868131868131869, Test accuracy = 0.9824561403508771\n",
      "log_reg, Train f1-score = 0.9867972264421968, Test f1-score = 0.9823623542652152\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9736842105263158\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.9736164257756981\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.9340659340659341, Test accuracy = 0.9122807017543859\n",
      "gnb, Train f1-score = 0.9333380562049505, Test f1-score = 0.9112731152204836\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.9230769230769231, Test accuracy = 0.9122807017543859\n",
      "kmeans, Train f1-score = 0.9216404510522157, Test f1-score = 0.9112731152204836\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8686813186813187 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': False}\n",
      "agglo, Train accuracy = 0.9148351648351648, Test accuracy = 0.9035087719298246\n",
      "agglo, Train f1-score = 0.9152882728246681, Test f1-score = 0.9044837459423354\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9560439560439561, Test accuracy = 0.9473684210526315\n",
      "affinity_propagation, Train f1-score = 0.9556930371614807, Test f1-score = 0.947087062795646\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: car_evaluation\n",
      "Dataset size: 1728\n",
      "Labels in dataset: ['acc' 'good' 'unacc' 'vgood']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 20, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9819102749638206, Test accuracy = 0.9624277456647399\n",
      "knn, Train f1-score = 0.9816256544326539, Test f1-score = 0.9596333417911395\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.9971098265895953\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.9971502121544917\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.01), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7091172214182344, Test accuracy = 0.7052023121387283\n",
      "log_reg, Train f1-score = 0.6243454614389254, Test f1-score = 0.6232788886846363\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9797687861271677\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.9798521627772763\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.7698986975397974, Test accuracy = 0.7716763005780347\n",
      "gnb, Train f1-score = 0.7141174776654589, Test f1-score = 0.7269497851433482\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 4, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7004341534008683, Test accuracy = 0.6994219653179191\n",
      "kmeans, Train f1-score = 0.577038519567694, Test f1-score = 0.5757146789351579\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7211310583661402 with params {'metric': 'l1', 'linkage': 'single', 'pca': True}\n",
      "agglo, Train accuracy = 0.6886877828054299, Test accuracy = 0.6907514450867052\n",
      "agglo, Train f1-score = 0.5639415499071259, Test f1-score = 0.5714935032854108\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7228654124457308, Test accuracy = 0.6936416184971098\n",
      "affinity_propagation, Train f1-score = 0.6589152293350833, Test f1-score = 0.6416053897474211\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: congress_voting_records\n",
      "Dataset size: 232\n",
      "Labels in dataset: ['democrat' 'republican']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.918918918918919, Test accuracy = 0.9574468085106383\n",
      "knn, Train f1-score = 0.9190185242131775, Test f1-score = 0.9574468085106383\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9621621621621622, Test accuracy = 1.0\n",
      "svm, Train f1-score = 0.9622064674668521, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.9837837837837838, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.9837771122087441, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9783783783783784, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 0.9783923261755774, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.9297297297297298, Test accuracy = 0.9787234042553191\n",
      "gnb, Train f1-score = 0.9297915057915058, Test f1-score = 0.9787427027548607\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8648648648648649, Test accuracy = 0.9574468085106383\n",
      "kmeans, Train f1-score = 0.8649517405544407, Test f1-score = 0.9574468085106383\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.9297297297297298 with params {'metric': 'l1', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.8648648648648649, Test accuracy = 0.9148936170212766\n",
      "agglo, Train f1-score = 0.8647167715660867, Test f1-score = 0.9149707061362935\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.9027027027027027, Test accuracy = 0.9787234042553191\n",
      "affinity_propagation, Train f1-score = 0.9027654677900983, Test f1-score = 0.9787427027548607\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: credit_approval\n",
      "Dataset size: 653\n",
      "Labels in dataset: ['+' '-']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9080459770114943, Test accuracy = 0.8320610687022901\n",
      "knn, Train f1-score = 0.9080119179476279, Test f1-score = 0.8303736440337486\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.921455938697318, Test accuracy = 0.8091603053435115\n",
      "svm, Train f1-score = 0.9215991959804102, Test f1-score = 0.8090028190054512\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8831417624521073, Test accuracy = 0.8625954198473282\n",
      "log_reg, Train f1-score = 0.8833853218184194, Test f1-score = 0.8628850313745821\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9252873563218391, Test accuracy = 0.816793893129771\n",
      "random_forest, Train f1-score = 0.9253246492457076, Test f1-score = 0.8164693664879367\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8390804597701149, Test accuracy = 0.7938931297709924\n",
      "gnb, Train f1-score = 0.8367797310495081, Test f1-score = 0.7886073701388141\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.5478927203065134, Test accuracy = 0.549618320610687\n",
      "kmeans, Train f1-score = 0.38992809410921037, Test f1-score = 0.38987703531004403\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6564850976361768 with params {'metric': 'euclidean', 'linkage': 'complete', 'pca': True}\n",
      "agglo, Train accuracy = 0.539568345323741, Test accuracy = 0.5725190839694656\n",
      "agglo, Train f1-score = 0.3807906252317733, Test f1-score = 0.4393105146515636\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8888888888888888, Test accuracy = 0.8244274809160306\n",
      "affinity_propagation, Train f1-score = 0.8890658878711447, Test f1-score = 0.8229609721950858\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ecoli\n",
      "Dataset size: 336\n",
      "Labels in dataset: ['cp' 'im' 'imL' 'imS' 'imU' 'om' 'omL' 'pp']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8917910447761194, Test accuracy = 0.8970588235294118\n",
      "knn, Train f1-score = 0.8845684398520219, Test f1-score = 0.8983699167273022\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8955223880597015, Test accuracy = 0.8823529411764706\n",
      "svm, Train f1-score = 0.8912260912789416, Test f1-score = 0.882988685384701\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8955223880597015, Test accuracy = 0.8676470588235294\n",
      "log_reg, Train f1-score = 0.8882656159339778, Test f1-score = 0.8696197014274818\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.8529411764705882\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.8495623249299721\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.8955223880597015, Test accuracy = 0.8382352941176471\n",
      "gnb, Train f1-score = 0.8966100486854829, Test f1-score = 0.8459870904883692\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 8, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8097014925373134, Test accuracy = 0.8382352941176471\n",
      "kmeans, Train f1-score = 0.765344046500763, Test f1-score = 0.7963351690596729\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7828314295604015 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': False}\n",
      "agglo, Train accuracy = 0.7289719626168224, Test accuracy = 0.6029411764705882\n",
      "agglo, Train f1-score = 0.7678392417494336, Test f1-score = 0.6726005906238465\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8097014925373134, Test accuracy = 0.8823529411764706\n",
      "affinity_propagation, Train f1-score = 0.8038905460573715, Test f1-score = 0.8854533108790075\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: fertility\n",
      "Dataset size: 100\n",
      "Labels in dataset: ['N' 'O']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9, Test accuracy = 0.8\n",
      "knn, Train f1-score = 0.8693693693693693, Test f1-score = 0.8274509803921569\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "svm, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.001), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "log_reg, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.95, Test accuracy = 0.85\n",
      "random_forest, Train f1-score = 0.9444444444444444, Test f1-score = 0.827027027027027\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "gnb, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "kmeans, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.915625 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.828125, Test accuracy = 0.85\n",
      "agglo, Train f1-score = 0.7644230769230769, Test f1-score = 0.827027027027027\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9, Test accuracy = 0.8\n",
      "affinity_propagation, Train f1-score = 0.888888888888889, Test f1-score = 0.8274509803921569\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: habermans_survival\n",
      "Dataset size: 306\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9877049180327869, Test accuracy = 0.6612903225806451\n",
      "knn, Train f1-score = 0.9876107881274389, Test f1-score = 0.6491189040454306\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.7745901639344263, Test accuracy = 0.7096774193548387\n",
      "svm, Train f1-score = 0.7431046330630733, Test f1-score = 0.685066085987745\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7622950819672131, Test accuracy = 0.7258064516129032\n",
      "log_reg, Train f1-score = 0.7180495529061102, Test f1-score = 0.6686352586759726\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8483606557377049, Test accuracy = 0.7258064516129032\n",
      "random_forest, Train f1-score = 0.8338028198126877, Test f1-score = 0.6971130661453242\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.7581967213114754, Test accuracy = 0.7258064516129032\n",
      "gnb, Train f1-score = 0.7182587202614457, Test f1-score = 0.6971130661453242\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7336065573770492, Test accuracy = 0.7419354838709677\n",
      "kmeans, Train f1-score = 0.6208774173545711, Test f1-score = 0.6320191158900836\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7987022501308216 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.7282051282051282, Test accuracy = 0.7419354838709677\n",
      "agglo, Train f1-score = 0.6274258063731748, Test f1-score = 0.6794044665012406\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7459016393442623, Test accuracy = 0.7258064516129032\n",
      "affinity_propagation, Train f1-score = 0.6948056135638999, Test f1-score = 0.6686352586759726\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: hayes_roth\n",
      "Dataset size: 132\n",
      "Labels in dataset: [1. 2. 3.]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9333333333333333, Test accuracy = 0.7407407407407407\n",
      "knn, Train f1-score = 0.9333333333333333, Test f1-score = 0.7407407407407407\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9333333333333333, Test accuracy = 0.8148148148148148\n",
      "svm, Train f1-score = 0.9333333333333333, Test f1-score = 0.8122722264598694\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.5619047619047619, Test accuracy = 0.5185185185185185\n",
      "log_reg, Train f1-score = 0.5619906530251358, Test f1-score = 0.508539390892332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8761904761904762, Test accuracy = 0.8518518518518519\n",
      "random_forest, Train f1-score = 0.872650282422474, Test f1-score = 0.8477366255144033\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8, Test accuracy = 0.6666666666666666\n",
      "gnb, Train f1-score = 0.7972813436865724, Test f1-score = 0.6572549019607843\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.4666666666666667, Test accuracy = 0.3333333333333333\n",
      "kmeans, Train f1-score = 0.35063977445239647, Test f1-score = 0.2037037037037037\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.5833333333333334 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.44047619047619047, Test accuracy = 0.4444444444444444\n",
      "agglo, Train f1-score = 0.2841769476152043, Test f1-score = 0.3124632569077014\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.5904761904761905, Test accuracy = 0.6296296296296297\n",
      "affinity_propagation, Train f1-score = 0.5852318123262594, Test f1-score = 0.6335821987995901\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: heart_disease\n",
      "Dataset size: 297\n",
      "Labels in dataset: [0 1 2 3 4]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.679324894514768, Test accuracy = 0.55\n",
      "knn, Train f1-score = 0.6363363425781582, Test f1-score = 0.46258828890407844\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.6919831223628692, Test accuracy = 0.6\n",
      "svm, Train f1-score = 0.674784540952961, Test f1-score = 0.5347407407407407\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.6751054852320675, Test accuracy = 0.6\n",
      "log_reg, Train f1-score = 0.6551415526651518, Test f1-score = 0.5432982982982982\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.6166666666666667\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.5455589073236132\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.6371308016877637, Test accuracy = 0.6\n",
      "gnb, Train f1-score = 0.6083583926053624, Test f1-score = 0.5475193614667299\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 5, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.5907172995780591, Test accuracy = 0.5833333333333334\n",
      "kmeans, Train f1-score = 0.4699361611700426, Test f1-score = 0.45156862745098036\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6267195767195768 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.5502645502645502, Test accuracy = 0.48333333333333334\n",
      "agglo, Train f1-score = 0.5253371736920611, Test f1-score = 0.4425\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.6075949367088608, Test accuracy = 0.5666666666666667\n",
      "affinity_propagation, Train f1-score = 0.549600985044023, Test f1-score = 0.47884317862165965\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ilpd\n",
      "Dataset size: 579\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.6982758620689655\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.6937699789158676\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9697624190064795, Test accuracy = 0.6724137931034483\n",
      "svm, Train f1-score = 0.969692546917593, Test f1-score = 0.6617481956696071\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.001), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.714902807775378, Test accuracy = 0.7155172413793104\n",
      "log_reg, Train f1-score = 0.5960524669361463, Test f1-score = 0.5968636284872639\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8423326133909287, Test accuracy = 0.7068965517241379\n",
      "random_forest, Train f1-score = 0.8236313190636412, Test f1-score = 0.658936660701907\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1e-05)}\n",
      "gnb, Train accuracy = 0.5593952483801296, Test accuracy = 0.5431034482758621\n",
      "gnb, Train f1-score = 0.5606038488370828, Test f1-score = 0.547894287406754\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.714902807775378, Test accuracy = 0.7155172413793104\n",
      "kmeans, Train f1-score = 0.5960524669361463, Test f1-score = 0.5968636284872639\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6776576576576576 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.7216216216216216, Test accuracy = 0.7068965517241379\n",
      "agglo, Train f1-score = 0.6072043786329501, Test f1-score = 0.5926506443747823\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.714902807775378, Test accuracy = 0.7155172413793104\n",
      "affinity_propagation, Train f1-score = 0.5960524669361463, Test f1-score = 0.5968636284872639\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: iris\n",
      "Dataset size: 150\n",
      "Labels in dataset: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.975, Test accuracy = 0.9\n",
      "knn, Train f1-score = 0.974996093139553, Test f1-score = 0.8997493734335839\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9833333333333333, Test accuracy = 0.9333333333333333\n",
      "svm, Train f1-score = 0.9833229101521785, Test f1-score = 0.9326599326599326\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.975, Test accuracy = 0.9\n",
      "log_reg, Train f1-score = 0.9749960931395532, Test f1-score = 0.8997493734335839\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.8997493734335839\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.975, Test accuracy = 0.9\n",
      "gnb, Train f1-score = 0.974996093139553, Test f1-score = 0.8997493734335839\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8333333333333334, Test accuracy = 0.8\n",
      "kmeans, Train f1-score = 0.8323905300649487, Test f1-score = 0.7979797979797979\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.9333333333333333 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.8333333333333334, Test accuracy = 0.8\n",
      "agglo, Train f1-score = 0.8222222222222223, Test f1-score = 0.7979797979797979\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.9\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.8997493734335839\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: lenses\n",
      "Dataset size: 24\n",
      "Labels in dataset: [1 2 3]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9473684210526315, Test accuracy = 0.8\n",
      "knn, Train f1-score = 0.9431578947368422, Test f1-score = 0.8133333333333332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9473684210526315, Test accuracy = 0.8\n",
      "svm, Train f1-score = 0.9431578947368422, Test f1-score = 0.8133333333333332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.9473684210526315, Test accuracy = 0.8\n",
      "log_reg, Train f1-score = 0.9431578947368422, Test f1-score = 0.8133333333333332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9473684210526315, Test accuracy = 0.8\n",
      "random_forest, Train f1-score = 0.9431578947368422, Test f1-score = 0.8133333333333332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8947368421052632, Test accuracy = 0.8\n",
      "gnb, Train f1-score = 0.9031100478468899, Test f1-score = 0.8133333333333332\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.6842105263157895, Test accuracy = 0.4\n",
      "kmeans, Train f1-score = 0.7105263157894738, Test f1-score = 0.38\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.52 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.6, Test accuracy = 0.6\n",
      "agglo, Train f1-score = 0.6317460317460317, Test f1-score = 0.5666666666666667\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.631578947368421, Test accuracy = 0.6\n",
      "affinity_propagation, Train f1-score = 0.4889643463497453, Test f1-score = 0.45\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mammographic_mass\n",
      "Dataset size: 830\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8298192771084337, Test accuracy = 0.8253012048192772\n",
      "knn, Train f1-score = 0.8298482410162399, Test f1-score = 0.8251678324159327\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8418674698795181, Test accuracy = 0.8734939759036144\n",
      "svm, Train f1-score = 0.8418857736264765, Test f1-score = 0.873471000707636\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8237951807228916, Test accuracy = 0.8313253012048193\n",
      "log_reg, Train f1-score = 0.823834753507639, Test f1-score = 0.8311289680765841\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.8569277108433735, Test accuracy = 0.8674698795180723\n",
      "random_forest, Train f1-score = 0.8567881541468038, Test f1-score = 0.8674698795180723\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.8087349397590361, Test accuracy = 0.8132530120481928\n",
      "gnb, Train f1-score = 0.808767492115597, Test f1-score = 0.8124552102593747\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7981927710843374, Test accuracy = 0.8072289156626506\n",
      "kmeans, Train f1-score = 0.7970902403319573, Test f1-score = 0.806555773508701\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.5687212381235576 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.7984934086629002, Test accuracy = 0.7951807228915663\n",
      "agglo, Train f1-score = 0.7983128118821643, Test f1-score = 0.7932942295497781\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9457831325301205, Test accuracy = 0.7771084337349398\n",
      "affinity_propagation, Train f1-score = 0.9457120931405332, Test f1-score = 0.7764828587175382\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mushroom\n",
      "Dataset size: 5644\n",
      "Labels in dataset: ['e' 'p']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(100.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8664451827242525, Test accuracy = 0.8715677590788308\n",
      "gnb, Train f1-score = 0.8611793955722903, Test f1-score = 0.8679182610559922\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.6179401993355482, Test accuracy = 0.6182462356067316\n",
      "kmeans, Train f1-score = 0.4720200290612401, Test f1-score = 0.472398327808975\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7445182724252492 with params {'metric': 'l1', 'linkage': 'complete', 'pca': True}\n",
      "agglo, Train accuracy = 0.8388704318936877, Test accuracy = 0.8609388839681134\n",
      "agglo, Train f1-score = 0.8270053801101479, Test f1-score = 0.8524839416948554\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.9991140642303433, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 0.9991140642303433, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spect_heart\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9436619718309859, Test accuracy = 0.8703703703703703\n",
      "knn, Train f1-score = 0.9449509154388005, Test f1-score = 0.8680289484887186\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9436619718309859, Test accuracy = 0.9074074074074074\n",
      "svm, Train f1-score = 0.9436619718309859, Test f1-score = 0.8963346022169552\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8450704225352113, Test accuracy = 0.9074074074074074\n",
      "log_reg, Train f1-score = 0.8278623145522753, Test f1-score = 0.8963346022169552\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9436619718309859, Test accuracy = 0.9074074074074074\n",
      "random_forest, Train f1-score = 0.9436619718309859, Test f1-score = 0.9016580152002979\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.6713615023474179, Test accuracy = 0.7777777777777778\n",
      "gnb, Train f1-score = 0.7026326596299626, Test f1-score = 0.7989754460342695\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7934272300469484, Test accuracy = 0.7962962962962963\n",
      "kmeans, Train f1-score = 0.7020377061671951, Test f1-score = 0.7059946544482627\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7716005471956224 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.788235294117647, Test accuracy = 0.7777777777777778\n",
      "agglo, Train f1-score = 0.7000773993808049, Test f1-score = 0.6967592592592593\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8169014084507042, Test accuracy = 0.8703703703703703\n",
      "affinity_propagation, Train f1-score = 0.8108472628578772, Test f1-score = 0.8758054439982151\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spectf_heart\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8075117370892019, Test accuracy = 0.7962962962962963\n",
      "knn, Train f1-score = 0.7967960581060384, Test f1-score = 0.7836476334406555\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.8333333333333334\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.8229844273605361\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8591549295774648, Test accuracy = 0.8148148148148148\n",
      "log_reg, Train f1-score = 0.8423766390654146, Test f1-score = 0.7861312399355876\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.8148148148148148\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.7472993827160495\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.001)}\n",
      "gnb, Train accuracy = 0.7136150234741784, Test accuracy = 0.6851851851851852\n",
      "gnb, Train f1-score = 0.7408583212779356, Test f1-score = 0.7156193375371458\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7934272300469484, Test accuracy = 0.7962962962962963\n",
      "kmeans, Train f1-score = 0.7020377061671951, Test f1-score = 0.7059946544482627\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7716005471956224 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.788235294117647, Test accuracy = 0.7777777777777778\n",
      "agglo, Train f1-score = 0.7000773993808049, Test f1-score = 0.6967592592592593\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.7934272300469484, Test accuracy = 0.7037037037037037\n",
      "affinity_propagation, Train f1-score = 0.7688190706292747, Test f1-score = 0.6578099838969403\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: statlog\n",
      "Dataset size: 1000\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.745\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.7291168581741116\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9275, Test accuracy = 0.73\n",
      "svm, Train f1-score = 0.9252120180333554, Test f1-score = 0.706907894736842\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7825, Test accuracy = 0.735\n",
      "log_reg, Train f1-score = 0.7703299856527976, Test f1-score = 0.7184939898672141\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.98, Test accuracy = 0.745\n",
      "random_forest, Train f1-score = 0.9797960174842157, Test f1-score = 0.7244462590588955\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.75125, Test accuracy = 0.74\n",
      "gnb, Train f1-score = 0.7302848591737481, Test f1-score = 0.706060606060606\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7, Test accuracy = 0.7\n",
      "kmeans, Train f1-score = 0.5764705882352941, Test f1-score = 0.5764705882352941\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7584375000000001 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.6921875, Test accuracy = 0.715\n",
      "agglo, Train f1-score = 0.569137765027729, Test f1-score = 0.654392666157372\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.75125, Test accuracy = 0.695\n",
      "affinity_propagation, Train f1-score = 0.7243532201427147, Test f1-score = 0.6532334471741765\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: wine_quality\n",
      "Dataset size: 6497\n",
      "Labels in dataset: [3 4 5 6 7 8 9]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.6807692307692308\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.670013673919213\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.683076923076923\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.6715875177742466\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1000.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.5526265152972869, Test accuracy = 0.5261538461538462\n",
      "log_reg, Train f1-score = 0.5202333721855271, Test f1-score = 0.49389487798467013\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.9926880892822783, Test accuracy = 0.6915384615384615\n",
      "random_forest, Train f1-score = 0.9926666871153029, Test f1-score = 0.6767124578568967\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.5045218395228016, Test accuracy = 0.48846153846153845\n",
      "gnb, Train f1-score = 0.4760834154252934, Test f1-score = 0.4608666731030936\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 7, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.4550702328266307, Test accuracy = 0.45153846153846156\n",
      "kmeans, Train f1-score = 0.35212090460284845, Test f1-score = 0.3510761368894076\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.4391016080383413 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.4378157324993986, Test accuracy = 0.4323076923076923\n",
      "agglo, Train f1-score = 0.2701196530024295, Test f1-score = 0.36118094561940817\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.539349624783529, Test accuracy = 0.536923076923077\n",
      "affinity_propagation, Train f1-score = 0.512431822326823, Test f1-score = 0.5049348135936399\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: zoo\n",
      "Dataset size: 101\n",
      "Labels in dataset: [1 2 3 4 5 6 7]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 1.0, Test accuracy = 0.9523809523809523\n",
      "gnb, Train f1-score = 1.0, Test f1-score = 0.9365079365079364\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "Cross validation best parameters:  {'n_clusters': 7, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8875, Test accuracy = 0.9523809523809523\n",
      "kmeans, Train f1-score = 0.8767865456554315, Test f1-score = 0.9365079365079364\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.921875 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.859375, Test accuracy = 0.8095238095238095\n",
      "agglo, Train f1-score = 0.852609970674487, Test f1-score = 0.8312925170068028\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.55, Test accuracy = 0.5714285714285714\n",
      "affinity_propagation, Train f1-score = 0.41345879120879125, Test f1-score = 0.43428571428571433\n"
     ]
    }
   ],
   "source": [
    "for i, (name, id) in enumerate(data_set_sorted.items()):\n",
    "        print(\"\\n\" + \"*\"*100)\n",
    "        print(f\"Current dataset: {name}\")\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "        # Set up dataset\n",
    "        X, y = import_dataset(dataset_id[name], ordinal_encoder)\n",
    "        labels = np.unique(y)\n",
    "        y = encode_categorical_features(y, ordinal_encoder)\n",
    "        print(f\"Dataset size: {len(X)}\")\n",
    "        print(f\"Labels in dataset: {labels}\")\n",
    "\n",
    "        # split the dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify = y)\n",
    "        print(\"*\"*100, end=\"\\n\\n\")\n",
    "\n",
    "        # KNN\n",
    "        clf_name = \"knn\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        # https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "        knn = KNeighborsClassifier()\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(knn, clf_name, knn_params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # SVM \n",
    "        svm = SVC()\n",
    "        clf_name = \"svm\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(svm, clf_name, svm_params, X_train, y_train, X_test, y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Logistic regression\n",
    "        log_reg = LogisticRegression()\n",
    "        clf_name = \"log_reg\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(log_reg, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    log_reg_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # Random forest\n",
    "        random_forest = RandomForestClassifier()\n",
    "        clf_name = \"random_forest\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(random_forest, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    random_forest_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # Gaussian naive bayes\n",
    "        gnb = GaussianNB()\n",
    "        clf_name = \"gnb\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(gnb, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    gnb_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "       \n",
    "        # K-means\n",
    "        clf_name = \"kmeans\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        kmeans_params = [{\"algorithm\": [\"lloyd\", \"elkan\"]}]\n",
    "        n_clusters = len(labels)\n",
    "        kmeans_params.append({\"n_clusters\": [n_clusters]})\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = clustering_classification(KMeans, clf_name, kmeans_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Agglomerative clustering\n",
    "        clf_name = \"agglomerative_clustering\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = agg_clustering(X_train, y_train, X_test, y_test, RANDOM_SEED)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "\n",
    "        # Affinity propagation\n",
    "        clf_name = \"affinity_propagation\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test =  clustering_classification(AffinityPropagation, clf_name, affinity_propagation_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Write metrics to tensorboard, step is dataset id\n",
    "        writer.add_scalars(\"Train accuracy\", metrics_dict[\"train_acc_dict\"], id[1])\n",
    "        writer.add_scalars(\"Test accuracy\", metrics_dict[\"test_acc_dict\"], id[1])\n",
    "        writer.add_scalars(\"Train f1\",  metrics_dict[\"train_f1_dict\"], id[1])\n",
    "        writer.add_scalars(\"Test f1\", metrics_dict[\"test_f1_dict\"], id[1])\n",
    "        writer.add_scalars(\"Train average accuracy\", metrics_dict[\"train_acc_avg\"], id[1])\n",
    "        writer.add_scalars(\"Test average accuracy\", metrics_dict[\"test_acc_avg\"], id[1])\n",
    "        writer.add_scalars(\"Train average f1\", metrics_dict[\"train_f1_avg\"], id[1])\n",
    "        writer.add_scalars(\"Test average f1\", metrics_dict[\"test_f1_avg\"], id[1])\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank  Classifier                     Avg. test acc.    Avg. train acc.   Avg. test F1      Avg train F1     \n",
      "____________________________________________________________________________________________________\n",
      "1     random_forest                  0.87              0.99              0.86              0.99             \n",
      "2     svm                            0.87              0.99              0.86              0.99             \n",
      "3     knn                            0.87              0.98              0.86              0.98             \n",
      "4     log_reg                        0.83              0.85              0.82              0.83             \n",
      "5     gnb                            0.78              0.81              0.77              0.81             \n",
      "6     kmeans                         0.77              0.74              0.71              0.68             \n",
      "7     agglomerative_clustering       0.70              0.72              0.68              0.65             \n",
      "8     affinity_propagation           0.61              0.61              0.52              0.53             \n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Rank':<5} {'Classifier':<30} {'Avg. test acc.':<17} {'Avg. train acc.':<17} {'Avg. test F1':<17} {'Avg train F1':<17}\")\n",
    "print(\"_\"*100)\n",
    "for i, clf in enumerate(sorted(metrics_dict[\"test_acc_avg\"].items(), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"{i+1:<5} {clf[0][:-4]:<30} {clf[1]:<17.2f} {metrics_dict['train_acc_avg'][clf[0]]:<8.2f}\\\n",
    "          {metrics_dict['test_f1_avg'][clf[0]]:<18.2f}{metrics_dict['train_f1_avg'][clf[0]]:<17.2}\")\n",
    "print(\"_\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedAILabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
