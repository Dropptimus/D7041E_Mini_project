{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import clustering_classification, test_classifier, write, save_metrics_to_dict, encode_categorical_features, import_dataset, agg_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acute_inflamations': (184, 1), 'balance_scale': (12, 2), 'balloons': (13, 3), 'breast_cancer_wisconsin_diagnostic': (17, 4), 'car_evaluation': (19, 5), 'congress_voting_records': (105, 6), 'credit_approval': (27, 7), 'ecoli': (39, 8), 'fertility': (244, 9), 'habermans_survival': (43, 10), 'hayes_roth': (44, 11), 'heart_disease': (45, 12), 'ilpd': (225, 13), 'iris': (53, 14), 'lenses': (58, 15), 'mammographic_mass': (161, 16), 'mushroom': (73, 17), 'spect_heart': (95, 18), 'spectf_heart': (96, 19), 'statlog': (144, 20), 'wine_quality': (186, 21), 'zoo': (111, 22)}\n"
     ]
    }
   ],
   "source": [
    "dataset_id = {\n",
    "    \"iris\": 53, \n",
    "    \"heart_disease\": 45, \n",
    "    \"wine_quality\": 186, \n",
    "    \"breast_cancer_wisconsin_diagnostic\": 17, \n",
    "    \"car_evaluation\": 19, \n",
    "    \"spect_heart\" : 95, \n",
    "    \"spectf_heart\" : 96,\n",
    "    \"mushroom\": 73, \n",
    "    \"statlog\" : 144, \n",
    "    \"credit_approval\" : 27, \n",
    "    \"zoo\" : 111, \n",
    "    \"balance_scale\" : 12, \n",
    "    \"ilpd\" : 225, \n",
    "    \"acute_inflamations\" : 184, \n",
    "    \"ecoli\" : 39, \n",
    "    \"mammographic_mass\" : 161, \n",
    "    \"hayes_roth\" : 44, \n",
    "    \"habermans_survival\" : 43, \n",
    "    \"congress_voting_records\" : 105, \n",
    "    \"balloons\" : 13, \n",
    "    \"lenses\" : 58, \n",
    "    \"fertility\" : 244, \n",
    "}\n",
    "# sort alphabetically and adds id for logging\n",
    "data_set_sorted = {}\n",
    "for i, name in enumerate(sorted(dataset_id.keys())):\n",
    "    data_set_sorted[name] = (dataset_id[name], i+1)\n",
    "print(data_set_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataset(uci_id, encoder):\n",
    "    # get the dataset\n",
    "    dataset = fetch_ucirepo(id=uci_id) \n",
    "    # load data into dataframe for easier preprocessing\n",
    "    df = pd.concat([dataset[\"data\"][\"features\"],dataset[\"data\"][\"targets\"] ],axis=1)\n",
    "    # remove nan values\n",
    "    initial_rows = df.shape[0]\n",
    "    df.dropna(inplace=True)\n",
    "    final_rows = df.shape[0]\n",
    "    if initial_rows > final_rows:\n",
    "        print(f\"Rows were removed. Initial rows: {initial_rows}, Final rows: {final_rows}, Removed rows: {initial_rows-final_rows}\")\n",
    "    else:\n",
    "        print(\"No rows were removed.\")\n",
    "    \n",
    "    X = df.iloc[:,:-1]\n",
    "    y = df.iloc[:,-1:]\n",
    "    # encode categorical data only for features not for target itself\n",
    "    # https://stackoverflow.com/questions/29803093/check-which-columns-in-dataframe-are-categorical\n",
    "    cols = X.columns\n",
    "    num_cols = X._get_numeric_data().columns\n",
    "    #print(num_cols)\n",
    "    categorical_cols = list(set(cols) - set(num_cols))\n",
    "    #print(categorical_cols)\n",
    "    X.loc[:, categorical_cols] = encode_categorical_features(X[categorical_cols], encoder)\n",
    "    \n",
    "    # check if encoding has worked\n",
    "    # https://stackoverflow.com/questions/26924904/check-if-dataframe-column-is-categorical\n",
    "    for c in X.columns:\n",
    "        if X[c].dtype.name == \"category\":\n",
    "            print(f\"WARNING: Column {c} still has categorical values!\")\n",
    "            \n",
    "    # last column is target\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: acute_inflamations\n",
      "No rows were removed.\n",
      "Dataset size: 120\n",
      "Labels in dataset: ['no' 'yes'], amount: 2\n",
      "Number of features: 7\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balance_scale\n",
      "No rows were removed.\n",
      "Dataset size: 625\n",
      "Labels in dataset: ['B' 'L' 'R'], amount: 3\n",
      "Number of features: 4\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balloons\n",
      "No rows were removed.\n",
      "Dataset size: 16\n",
      "Labels in dataset: ['F' 'T'], amount: 2\n",
      "Number of features: 4\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: breast_cancer_wisconsin_diagnostic\n",
      "No rows were removed.\n",
      "Dataset size: 569\n",
      "Labels in dataset: ['B' 'M'], amount: 2\n",
      "Number of features: 30\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: car_evaluation\n",
      "No rows were removed.\n",
      "Dataset size: 1728\n",
      "Labels in dataset: ['acc' 'good' 'unacc' 'vgood'], amount: 4\n",
      "Number of features: 6\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: congress_voting_records\n",
      "Rows were removed. Initial rows: 435, Final rows: 232\n",
      "Dataset size: 232\n",
      "Labels in dataset: ['democrat' 'republican'], amount: 2\n",
      "Number of features: 16\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: credit_approval\n",
      "Rows were removed. Initial rows: 690, Final rows: 653\n",
      "Dataset size: 653\n",
      "Labels in dataset: ['+' '-'], amount: 2\n",
      "Number of features: 15\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ecoli\n",
      "No rows were removed.\n",
      "Dataset size: 336\n",
      "Labels in dataset: ['cp' 'im' 'imL' 'imS' 'imU' 'om' 'omL' 'pp'], amount: 8\n",
      "Number of features: 7\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: fertility\n",
      "No rows were removed.\n",
      "Dataset size: 100\n",
      "Labels in dataset: ['N' 'O'], amount: 2\n",
      "Number of features: 9\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: habermans_survival\n",
      "No rows were removed.\n",
      "Dataset size: 306\n",
      "Labels in dataset: [1 2], amount: 2\n",
      "Number of features: 3\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: hayes_roth\n",
      "Rows were removed. Initial rows: 160, Final rows: 132\n",
      "Dataset size: 132\n",
      "Labels in dataset: [1. 2. 3.], amount: 3\n",
      "Number of features: 4\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: heart_disease\n",
      "Rows were removed. Initial rows: 303, Final rows: 297\n",
      "Dataset size: 297\n",
      "Labels in dataset: [0 1 2 3 4], amount: 5\n",
      "Number of features: 13\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ilpd\n",
      "Rows were removed. Initial rows: 583, Final rows: 579\n",
      "Dataset size: 579\n",
      "Labels in dataset: [1 2], amount: 2\n",
      "Number of features: 10\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: iris\n",
      "No rows were removed.\n",
      "Dataset size: 150\n",
      "Labels in dataset: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica'], amount: 3\n",
      "Number of features: 4\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: lenses\n",
      "No rows were removed.\n",
      "Dataset size: 24\n",
      "Labels in dataset: [1 2 3], amount: 3\n",
      "Number of features: 3\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mammographic_mass\n",
      "Rows were removed. Initial rows: 961, Final rows: 830\n",
      "Dataset size: 830\n",
      "Labels in dataset: [0 1], amount: 2\n",
      "Number of features: 5\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mushroom\n",
      "Rows were removed. Initial rows: 8124, Final rows: 5644\n",
      "Dataset size: 5644\n",
      "Labels in dataset: ['e' 'p'], amount: 2\n",
      "Number of features: 22\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spect_heart\n",
      "No rows were removed.\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1], amount: 2\n",
      "Number of features: 22\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spectf_heart\n",
      "No rows were removed.\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1], amount: 2\n",
      "Number of features: 44\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: statlog\n",
      "No rows were removed.\n",
      "Dataset size: 1000\n",
      "Labels in dataset: [1 2], amount: 2\n",
      "Number of features: 20\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: wine_quality\n",
      "No rows were removed.\n",
      "Dataset size: 6497\n",
      "Labels in dataset: [3 4 5 6 7 8 9], amount: 7\n",
      "Number of features: 11\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: zoo\n",
      "No rows were removed.\n",
      "Dataset size: 101\n",
      "Labels in dataset: [1 2 3 4 5 6 7], amount: 7\n",
      "Number of features: 16\n"
     ]
    }
   ],
   "source": [
    "for i, (name, id) in enumerate(data_set_sorted.items()):\n",
    "        print(\"\\n\" + \"*\"*100)\n",
    "        print(f\"Current dataset: {name}\")\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "        # Set up dataset\n",
    "        X, y = import_dataset(dataset_id[name], ordinal_encoder)\n",
    "        labels = np.unique(y)\n",
    "        y = encode_categorical_features(y, ordinal_encoder)\n",
    "        print(f\"Dataset size: {len(X)}\")\n",
    "        print(f\"Labels in dataset: {labels}, amount: {len(labels)}\")\n",
    "        print(f\"Number of features: {X.shape[1]}\")\n",
    "        #print(X.head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "D7041EMiniProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
