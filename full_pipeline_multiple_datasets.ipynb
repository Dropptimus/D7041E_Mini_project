{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from clustering import clustering_classification, test_classifier, write, save_metrics_to_dict, encode_categorical_features, import_dataset, agg_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = SummaryWriter(log_dir=\"C:\\\\awilde\\\\britta\\\\LTU\\\\AppliedAI\\\\runs\")\n",
    "writer = SummaryWriter()\n",
    "metrics_dict={\n",
    "\"train_acc_dict\" : {},\n",
    "\"train_f1_dict\" : {},\n",
    "\"test_acc_dict\" : {},\n",
    "\"test_f1_dict\" : {},\n",
    "\"train_acc_avg\" : {},\n",
    "\"train_f1_avg\" : {},\n",
    "\"test_acc_avg\" : {},\n",
    "\"test_f1_avg\" : {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# Launch tensorboard\n",
    "# images=21 change this to how many datasets you use\n",
    "%tensorboard --logdir runs/ --port 6006 --samples_per_plugin images=22\n",
    "# If in use (Mac) use to find the process PID\n",
    "% lsof -i :6006\n",
    "# Kill the process with \n",
    "% kill -9 <PID>\n",
    "# Then launch using bash with first command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our chosen datasets\n",
    "TODO\n",
    "We have chosen the datasets based on the following criteria:\n",
    "- datasets where we do not need to do any special preprocessing so that it is easy to do in only one pipeline\n",
    "- rather small datasets to ensure we do not need high computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acute_inflamations': (184, 1), 'balance_scale': (12, 2), 'balloons': (13, 3), 'breast_cancer_wisconsin_diagnostic': (17, 4), 'car_evaluation': (19, 5), 'congress_voting_records': (105, 6), 'credit_approval': (27, 7), 'ecoli': (39, 8), 'fertility': (244, 9), 'habermans_survival': (43, 10), 'hayes_roth': (44, 11), 'heart_disease': (45, 12), 'ilpd': (225, 13), 'iris': (53, 14), 'lenses': (58, 15), 'mammographic_mass': (161, 16), 'mushroom': (73, 17), 'spect_heart': (95, 18), 'spectf_heart': (96, 19), 'statlog': (144, 20), 'wine_quality': (186, 21), 'zoo': (111, 22)}\n"
     ]
    }
   ],
   "source": [
    "# Dataset that seems useful\n",
    "dataset_id = {\n",
    "    \"iris\": 53, \n",
    "    \"heart_disease\": 45, \n",
    "    \"wine_quality\": 186, \n",
    "    \"breast_cancer_wisconsin_diagnostic\": 17, \n",
    "    \"car_evaluation\": 19, \n",
    "    \"spect_heart\" : 95, \n",
    "    \"spectf_heart\" : 96,\n",
    "    \"mushroom\": 73, \n",
    "    \"statlog\" : 144, \n",
    "    \"credit_approval\" : 27, \n",
    "    \"zoo\" : 111, \n",
    "    \"balance_scale\" : 12, \n",
    "    \"ilpd\" : 225, \n",
    "    \"acute_inflamations\" : 184, \n",
    "    \"ecoli\" : 39, \n",
    "    \"mammographic_mass\" : 161, \n",
    "    \"hayes_roth\" : 44, \n",
    "    \"habermans_survival\" : 43, \n",
    "    \"congress_voting_records\" : 105, \n",
    "    \"balloons\" : 13, \n",
    "    \"lenses\" : 58, \n",
    "    \"fertility\" : 244, \n",
    "}\n",
    "\n",
    "# sort alphabetically and adds id for logging\n",
    "data_set_sorted = {}\n",
    "for i, name in enumerate(sorted(dataset_id.keys())):\n",
    "    data_set_sorted[name] = (dataset_id[name], i+1)\n",
    "\n",
    "print(data_set_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preprocess datasets\n",
    "For the preprocessing we will do the following steps:\n",
    "1. Remove any missing values. In the article the following is written: \"Given that our classifiers are not oriented to data with missing features, the missing inputs are treated as zero, which should not bias the comparison results.\" We therefore also decided to just remove missing values and to more focus on the full pipeline instead of single datasets. Another way could have been interpolation.\n",
    "2. Encode categorical data into numerical data. This we have to do to use the classifiers later on.\n",
    "3. Remove certain columns if they are highly correlated to others. <span style=\"color: red;\">ALERT!</span>\n",
    "4. Split the data into a train and a test set. We will use a 80/20 split.\n",
    "5. Scale the data so that we have zero mean and standard deviation of one. This is done with the Standard scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "knn_params = [{'knn__n_neighbors': [3, 5, 7, 9],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__leaf_size': [15, 20]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "svm_params = [{'svm__C': [0.1, 1, 10, 100, 1000],  \n",
    "        'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "        'svm__kernel': ['rbf']} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/how-to-optimize-logistic-regression-performance/\n",
    "# and from here https://www.kaggle.com/code/enespolat/grid-search-with-logistic-regression\n",
    "log_reg_params = [\n",
    "    {'log_reg__penalty':['l1','l2'],\n",
    "    'log_reg__C' : np.logspace(-3,3,7),\n",
    "    'log_reg__max_iter'  : [100,1000,2500,5000]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.datacamp.com/tutorial/random-forests-classifier-python\n",
    "random_forest_params = [\n",
    "    {\"random_forest__n_estimators\": [100, 500],\n",
    "     \"random_forest__max_depth\" : [5, 10, 15]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/akshaysharma001/naive-bayes-with-hyperpameter-tuning#Hyperparameter-Tuning-to-improve-Accuracy\n",
    "gnb_params = [\n",
    "    {'gnb__var_smoothing': np.logspace(0,-9, num=10)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already use k-means++ and we set the no. clusters to no. of labels\n",
    "kmeans_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://letsdatascience.com/affinity-propagation-clustering/\n",
    "affinity_propagation_params = [\n",
    "    {\"damping\": [0.5, 0.7]}, \n",
    "    {\"preference\": [-50,-10,0,10,50]}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: acute_inflamations\n",
      "Dataset size: 120\n",
      "Labels in dataset: ['no' 'yes']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "gnb, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7604166666666666, Test accuracy = 0.7083333333333334\n",
      "kmeans, Train f1-score = 0.756208865132177, Test f1-score = 0.6975308641975309\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8305263157894738 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.5526315789473685, Test accuracy = 0.9166666666666666\n",
      "agglo, Train f1-score = 0.5589369830495902, Test f1-score = 0.9148148148148149\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balance_scale\n",
      "Dataset size: 625\n",
      "Labels in dataset: ['B' 'L' 'R']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.888\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.8587163947163947\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.972, Test accuracy = 0.968\n",
      "svm, Train f1-score = 0.9734417862838916, Test f1-score = 0.9703834586466165\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(100.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.908, Test accuracy = 0.88\n",
      "log_reg, Train f1-score = 0.9129388054666053, Test f1-score = 0.8758727326791556\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.914, Test accuracy = 0.824\n",
      "random_forest, Train f1-score = 0.8825217254782151, Test f1-score = 0.7929904761904761\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.906, Test accuracy = 0.888\n",
      "gnb, Train f1-score = 0.8693414078405891, Test f1-score = 0.851000208347802\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.74, Test accuracy = 0.744\n",
      "kmeans, Train f1-score = 0.7076584163778162, Test f1-score = 0.7104000000000001\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.618 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.65, Test accuracy = 0.496\n",
      "agglo, Train f1-score = 0.693780972787658, Test f1-score = 0.49242927967337413\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.776\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.776978443385523\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balloons\n",
      "Dataset size: 16\n",
      "Labels in dataset: ['F' 'T']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9166666666666666, Test accuracy = 0.75\n",
      "knn, Train f1-score = 0.9172494172494172, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 0.75\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.75\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.8333333333333334, Test accuracy = 0.25\n",
      "gnb, Train f1-score = 0.8333333333333334, Test f1-score = 0.2\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'elkan'}\n",
      "kmeans, Train accuracy = 0.5833333333333334, Test accuracy = 0.5\n",
      "kmeans, Train f1-score = 0.4298245614035088, Test f1-score = 0.3333333333333333\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6888888888888889 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.7777777777777778, Test accuracy = 0.75\n",
      "agglo, Train f1-score = 0.7833333333333334, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.75\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.7333333333333334\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: breast_cancer_wisconsin_diagnostic\n",
      "Dataset size: 569\n",
      "Labels in dataset: ['B' 'M']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9714285714285714, Test accuracy = 0.956140350877193\n",
      "knn, Train f1-score = 0.9712214031985518, Test f1-score = 0.9557756825927252\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9868131868131869, Test accuracy = 0.9824561403508771\n",
      "svm, Train f1-score = 0.9867634237020464, Test f1-score = 0.9823623542652152\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.9802197802197802, Test accuracy = 0.9824561403508771\n",
      "log_reg, Train f1-score = 0.9801581675948969, Test f1-score = 0.9823623542652152\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9736842105263158\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.9734654095556351\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.9494505494505494, Test accuracy = 0.9385964912280702\n",
      "gnb, Train f1-score = 0.9488522774634134, Test f1-score = 0.9376836024305945\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.9076923076923077, Test accuracy = 0.8947368421052632\n",
      "kmeans, Train f1-score = 0.9065251518667669, Test f1-score = 0.8927935222672067\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.9236263736263737 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.8818681318681318, Test accuracy = 0.9035087719298246\n",
      "agglo, Train f1-score = 0.882108599545197, Test f1-score = 0.9027065017039956\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.9648351648351648, Test accuracy = 0.9473684210526315\n",
      "affinity_propagation, Train f1-score = 0.9647483758982017, Test f1-score = 0.947087062795646\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: car_evaluation\n",
      "Dataset size: 1728\n",
      "Labels in dataset: ['acc' 'good' 'unacc' 'vgood']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 20, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9797395079594791, Test accuracy = 0.9624277456647399\n",
      "knn, Train f1-score = 0.978987814773178, Test f1-score = 0.9587169241227403\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.9942196531791907\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.9941935182994237\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.01), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7026049204052098, Test accuracy = 0.7109826589595376\n",
      "log_reg, Train f1-score = 0.6150351449562932, Test f1-score = 0.6197238819684671\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9826589595375722\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.982610094750015\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.7713458755426917, Test accuracy = 0.7514450867052023\n",
      "gnb, Train f1-score = 0.7177347335089737, Test f1-score = 0.6726981948268703\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 4\n",
      "Cross validation best parameters:  {'n_clusters': 4, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7004341534008683, Test accuracy = 0.6994219653179191\n",
      "kmeans, Train f1-score = 0.577038519567694, Test f1-score = 0.5757146789351579\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7074146070535963 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': True}\n",
      "agglo, Train accuracy = 0.6923076923076923, Test accuracy = 0.6878612716763006\n",
      "agglo, Train f1-score = 0.5703152802993815, Test f1-score = 0.570076807348167\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7409551374819102, Test accuracy = 0.7427745664739884\n",
      "affinity_propagation, Train f1-score = 0.6936731398200907, Test f1-score = 0.6896091450180828\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: congress_voting_records\n",
      "Dataset size: 232\n",
      "Labels in dataset: ['democrat' 'republican']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.9148936170212766\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.9147394387912426\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9675675675675676, Test accuracy = 1.0\n",
      "svm, Train f1-score = 0.9676017629625877, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.9891891891891892, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.9891891891891892, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9783783783783784, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 0.9783923261755774, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.9459459459459459, Test accuracy = 1.0\n",
      "gnb, Train f1-score = 0.9459459459459459, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8972972972972973, Test accuracy = 0.8723404255319149\n",
      "kmeans, Train f1-score = 0.8974053769633881, Test f1-score = 0.8712959381044488\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.9581081081081082 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.8986486486486487, Test accuracy = 0.8936170212765957\n",
      "agglo, Train f1-score = 0.8987736309042542, Test f1-score = 0.8936170212765957\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.9148936170212766\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.9147394387912426\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: credit_approval\n",
      "Dataset size: 653\n",
      "Labels in dataset: ['+' '-']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9042145593869731, Test accuracy = 0.8091603053435115\n",
      "knn, Train f1-score = 0.9041790811954459, Test f1-score = 0.8081401965046991\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8984674329501916, Test accuracy = 0.8015267175572519\n",
      "svm, Train f1-score = 0.8986730180879581, Test f1-score = 0.8017829624054761\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.01), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8946360153256705, Test accuracy = 0.8015267175572519\n",
      "log_reg, Train f1-score = 0.8947476812363195, Test f1-score = 0.801175147028598\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9329501915708812, Test accuracy = 0.8320610687022901\n",
      "random_forest, Train f1-score = 0.9329618513285213, Test f1-score = 0.8313842166795159\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.842911877394636, Test accuracy = 0.7938931297709924\n",
      "gnb, Train f1-score = 0.840975297901508, Test f1-score = 0.7874289206930271\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8160919540229885, Test accuracy = 0.7862595419847328\n",
      "kmeans, Train f1-score = 0.8130757415320741, Test f1-score = 0.7774822459238769\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.758465227817746 with params {'metric': 'euclidean', 'linkage': 'complete', 'pca': True}\n",
      "agglo, Train accuracy = 0.592326139088729, Test accuracy = 0.6641221374045801\n",
      "agglo, Train f1-score = 0.4858506206016198, Test f1-score = 0.603571412894135\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.8295019157088123, Test accuracy = 0.7633587786259542\n",
      "affinity_propagation, Train f1-score = 0.8297216079573786, Test f1-score = 0.7635256526141124\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ecoli\n",
      "Dataset size: 336\n",
      "Labels in dataset: ['cp' 'im' 'imL' 'imS' 'imU' 'om' 'omL' 'pp']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.9264705882352942\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.9264684395090591\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8843283582089553, Test accuracy = 0.8970588235294118\n",
      "svm, Train f1-score = 0.8780685131552103, Test f1-score = 0.897455780805731\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8843283582089553, Test accuracy = 0.8970588235294118\n",
      "log_reg, Train f1-score = 0.8795170564273465, Test f1-score = 0.897650847778725\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.8676470588235294\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.8714939430791874\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.9029850746268657, Test accuracy = 0.8823529411764706\n",
      "gnb, Train f1-score = 0.9029857569600259, Test f1-score = 0.8824477983054884\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 8\n",
      "Cross validation best parameters:  {'n_clusters': 8, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7425373134328358, Test accuracy = 0.7058823529411765\n",
      "kmeans, Train f1-score = 0.7102611507260603, Test f1-score = 0.6671333142560764\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7865697473174109 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.7476635514018691, Test accuracy = 0.7941176470588235\n",
      "agglo, Train f1-score = 0.698241965385305, Test f1-score = 0.7915680203970132\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8283582089552238, Test accuracy = 0.8382352941176471\n",
      "affinity_propagation, Train f1-score = 0.8236731661665815, Test f1-score = 0.8315249683536129\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: fertility\n",
      "Dataset size: 100\n",
      "Labels in dataset: ['N' 'O']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "knn, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "svm, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.001), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "log_reg, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.95, Test accuracy = 0.9\n",
      "random_forest, Train f1-score = 0.9444444444444444, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "gnb, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "kmeans, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.909375 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.796875, Test accuracy = 0.85\n",
      "agglo, Train f1-score = 0.7910029498525074, Test f1-score = 0.827027027027027\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "affinity_propagation, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: habermans_survival\n",
      "Dataset size: 306\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.7909836065573771, Test accuracy = 0.6451612903225806\n",
      "knn, Train f1-score = 0.7688076661268871, Test f1-score = 0.600215053763441\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.7991803278688525, Test accuracy = 0.6612903225806451\n",
      "svm, Train f1-score = 0.7711295821834653, Test f1-score = 0.5906670842467898\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7704918032786885, Test accuracy = 0.6774193548387096\n",
      "log_reg, Train f1-score = 0.7243405541867483, Test f1-score = 0.6199183485711001\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8688524590163934, Test accuracy = 0.6290322580645161\n",
      "random_forest, Train f1-score = 0.8614529871941801, Test f1-score = 0.5902117953730857\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.7704918032786885, Test accuracy = 0.6774193548387096\n",
      "gnb, Train f1-score = 0.7310230569971898, Test f1-score = 0.6199183485711001\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7336065573770492, Test accuracy = 0.7419354838709677\n",
      "kmeans, Train f1-score = 0.6208774173545711, Test f1-score = 0.6320191158900836\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7364730507587651 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': True}\n",
      "agglo, Train accuracy = 0.7435897435897436, Test accuracy = 0.7096774193548387\n",
      "agglo, Train f1-score = 0.6392808375056896, Test f1-score = 0.6159464394400487\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7663934426229508, Test accuracy = 0.7096774193548387\n",
      "affinity_propagation, Train f1-score = 0.717598962458514, Test f1-score = 0.6393300248138957\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: hayes_roth\n",
      "Dataset size: 132\n",
      "Labels in dataset: [1. 2. 3.]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9333333333333333, Test accuracy = 0.7037037037037037\n",
      "knn, Train f1-score = 0.9331296154825566, Test f1-score = 0.7019364078187608\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9333333333333333, Test accuracy = 0.7407407407407407\n",
      "svm, Train f1-score = 0.9331296154825566, Test f1-score = 0.7334204793028323\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.5904761904761905, Test accuracy = 0.7037037037037037\n",
      "log_reg, Train f1-score = 0.5933444998458677, Test f1-score = 0.7020933977455717\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.9333333333333333, Test accuracy = 0.7777777777777778\n",
      "random_forest, Train f1-score = 0.9332723298256317, Test f1-score = 0.7746913580246912\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.01)}\n",
      "gnb, Train accuracy = 0.8285714285714286, Test accuracy = 0.7777777777777778\n",
      "gnb, Train f1-score = 0.8260557053009883, Test f1-score = 0.7743289848553006\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'elkan'}\n",
      "kmeans, Train accuracy = 0.42857142857142855, Test accuracy = 0.48148148148148145\n",
      "kmeans, Train f1-score = 0.3623827909542195, Test f1-score = 0.39351851851851855\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6000000000000001 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.5238095238095238, Test accuracy = 0.48148148148148145\n",
      "agglo, Train f1-score = 0.42886719905353454, Test f1-score = 0.45177045177045183\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9333333333333333, Test accuracy = 0.7407407407407407\n",
      "affinity_propagation, Train f1-score = 0.9331296154825566, Test f1-score = 0.7334204793028323\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: heart_disease\n",
      "Dataset size: 297\n",
      "Labels in dataset: [0 1 2 3 4]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.5666666666666667\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.508994708994709\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.6962025316455697, Test accuracy = 0.6166666666666667\n",
      "svm, Train f1-score = 0.6634609048329984, Test f1-score = 0.5726902587519026\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.6708860759493671, Test accuracy = 0.5833333333333334\n",
      "log_reg, Train f1-score = 0.6470936164837666, Test f1-score = 0.5441526610644257\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.55\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.4946682946682947\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.6329113924050633, Test accuracy = 0.5333333333333333\n",
      "gnb, Train f1-score = 0.5992540247579035, Test f1-score = 0.46976351351351353\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 5\n",
      "Cross validation best parameters:  {'n_clusters': 5, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.6160337552742616, Test accuracy = 0.65\n",
      "kmeans, Train f1-score = 0.5444325136124807, Test f1-score = 0.5660984271943176\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.6600529100529101 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.5502645502645502, Test accuracy = 0.6333333333333333\n",
      "agglo, Train f1-score = 0.4151326755474049, Test f1-score = 0.6105458089668616\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.6118143459915611, Test accuracy = 0.5166666666666667\n",
      "affinity_propagation, Train f1-score = 0.5822235933867003, Test f1-score = 0.4963292847503374\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ilpd\n",
      "Dataset size: 579\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.6637931034482759\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.6549294377832654\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.857451403887689, Test accuracy = 0.6637931034482759\n",
      "svm, Train f1-score = 0.8444991631315943, Test f1-score = 0.6282821377741419\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(100.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.7365010799136069, Test accuracy = 0.7241379310344828\n",
      "log_reg, Train f1-score = 0.7161304278756292, Test f1-score = 0.702785311464118\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.8596112311015118, Test accuracy = 0.6896551724137931\n",
      "random_forest, Train f1-score = 0.8490610634349449, Test f1-score = 0.6466454272863568\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.0001)}\n",
      "gnb, Train accuracy = 0.5809935205183585, Test accuracy = 0.5\n",
      "gnb, Train f1-score = 0.5870492288868011, Test f1-score = 0.4919642857142858\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.714902807775378, Test accuracy = 0.7155172413793104\n",
      "kmeans, Train f1-score = 0.5960524669361463, Test f1-score = 0.5968636284872639\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7018424876489393 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.7135135135135136, Test accuracy = 0.7068965517241379\n",
      "agglo, Train f1-score = 0.5964702873220223, Test f1-score = 0.5926506443747823\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7257019438444925, Test accuracy = 0.6637931034482759\n",
      "affinity_propagation, Train f1-score = 0.6931668153572936, Test f1-score = 0.6458957739175525\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: iris\n",
      "Dataset size: 150\n",
      "Labels in dataset: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.975, Test accuracy = 0.9333333333333333\n",
      "knn, Train f1-score = 0.974996093139553, Test f1-score = 0.9326599326599326\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9833333333333333, Test accuracy = 0.9666666666666667\n",
      "svm, Train f1-score = 0.9833333333333333, Test f1-score = 0.9665831244778613\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.975, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.9749960931395532, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.9333333333333333\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.9333333333333333\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.9583333333333334, Test accuracy = 0.9333333333333333\n",
      "gnb, Train f1-score = 0.9583268218992551, Test f1-score = 0.9333333333333333\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8333333333333334, Test accuracy = 0.8\n",
      "kmeans, Train f1-score = 0.8316498316498316, Test f1-score = 0.8\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8041666666666667 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.8541666666666666, Test accuracy = 0.7666666666666667\n",
      "agglo, Train f1-score = 0.8512731481481483, Test f1-score = 0.7340930674264008\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': 0, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 0.9666666666666667\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 0.9665831244778613\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: lenses\n",
      "Dataset size: 24\n",
      "Labels in dataset: [1 2 3]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.7368421052631579, Test accuracy = 0.4\n",
      "knn, Train f1-score = 0.6736842105263158, Test f1-score = 0.34\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8947368421052632, Test accuracy = 0.8\n",
      "svm, Train f1-score = 0.8897628687102371, Test f1-score = 0.7142857142857142\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8947368421052632, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.8923976608187134, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8947368421052632, Test accuracy = 0.8\n",
      "random_forest, Train f1-score = 0.8897628687102371, Test f1-score = 0.7142857142857142\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8421052631578947, Test accuracy = 1.0\n",
      "gnb, Train f1-score = 0.8469089390142022, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3, 'algorithm': 'elkan'}\n",
      "kmeans, Train accuracy = 0.7368421052631579, Test accuracy = 0.4\n",
      "kmeans, Train f1-score = 0.6736842105263158, Test f1-score = 0.34\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.5733333333333334 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': False}\n",
      "agglo, Train accuracy = 0.8666666666666667, Test accuracy = 0.6\n",
      "agglo, Train f1-score = 0.8656084656084656, Test f1-score = 0.6133333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.6842105263157895, Test accuracy = 0.6\n",
      "affinity_propagation, Train f1-score = 0.646301067353699, Test f1-score = 0.5800000000000001\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mammographic_mass\n",
      "Dataset size: 830\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 20, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8418674698795181, Test accuracy = 0.8012048192771084\n",
      "knn, Train f1-score = 0.8418599304415901, Test f1-score = 0.8011687153977138\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8493975903614458, Test accuracy = 0.8493975903614458\n",
      "svm, Train f1-score = 0.8494262856443239, Test f1-score = 0.8494139869221032\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8283132530120482, Test accuracy = 0.7951807228915663\n",
      "log_reg, Train f1-score = 0.8282758688537492, Test f1-score = 0.7951807228915663\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8674698795180723, Test accuracy = 0.8433734939759037\n",
      "random_forest, Train f1-score = 0.867228529502626, Test f1-score = 0.8433051975343233\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8117469879518072, Test accuracy = 0.7891566265060241\n",
      "gnb, Train f1-score = 0.8117858578737689, Test f1-score = 0.7888112961399739\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.802710843373494, Test accuracy = 0.7710843373493976\n",
      "kmeans, Train f1-score = 0.8012946547145712, Test f1-score = 0.7705852479686187\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7954094275236113 with params {'metric': 'euclidean', 'linkage': 'ward', 'pca': True}\n",
      "agglo, Train accuracy = 0.7890772128060264, Test accuracy = 0.7650602409638554\n",
      "agglo, Train f1-score = 0.7879137597094048, Test f1-score = 0.7646762269739302\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8253012048192772, Test accuracy = 0.7710843373493976\n",
      "affinity_propagation, Train f1-score = 0.8251823071011621, Test f1-score = 0.7710843373493976\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mushroom\n",
      "Dataset size: 5644\n",
      "Labels in dataset: ['e' 'p']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(100.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 10, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.8699889258028793, Test accuracy = 0.8662533215234721\n",
      "gnb, Train f1-score = 0.8648933076628132, Test f1-score = 0.8612948868634539\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7198228128460686, Test accuracy = 0.7068201948627104\n",
      "kmeans, Train f1-score = 0.7199609961199867, Test f1-score = 0.7070128994306938\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8485049833887043 with params {'metric': 'l1', 'linkage': 'complete', 'pca': True}\n",
      "agglo, Train accuracy = 0.8493909191583611, Test accuracy = 0.8396811337466785\n",
      "agglo, Train f1-score = 0.8389644465832518, Test f1-score = 0.8275762000059197\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.9997785160575858, Test accuracy = 0.9982285208148804\n",
      "affinity_propagation, Train f1-score = 0.9997785037918323, Test f1-score = 0.9982277281078558\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spect_heart\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.863849765258216, Test accuracy = 0.8333333333333334\n",
      "knn, Train f1-score = 0.8620460153827341, Test f1-score = 0.8134022839905193\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9342723004694836, Test accuracy = 0.8703703703703703\n",
      "svm, Train f1-score = 0.9337013416568725, Test f1-score = 0.8450019912385502\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8497652582159625, Test accuracy = 0.8703703703703703\n",
      "log_reg, Train f1-score = 0.836467644536396, Test f1-score = 0.8450019912385502\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 0.8544600938967136, Test accuracy = 0.8518518518518519\n",
      "random_forest, Train f1-score = 0.8425995714543643, Test f1-score = 0.815827986040752\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.1)}\n",
      "gnb, Train accuracy = 0.755868544600939, Test accuracy = 0.7777777777777778\n",
      "gnb, Train f1-score = 0.7776294230708637, Test f1-score = 0.7894517406712528\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7934272300469484, Test accuracy = 0.7962962962962963\n",
      "kmeans, Train f1-score = 0.7020377061671951, Test f1-score = 0.7059946544482627\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8238850889192888 with params {'metric': 'l1', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.7705882352941177, Test accuracy = 0.7777777777777778\n",
      "agglo, Train f1-score = 0.6758647645104554, Test f1-score = 0.6967592592592593\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7981220657276995, Test accuracy = 0.7962962962962963\n",
      "affinity_propagation, Train f1-score = 0.8081343471773763, Test f1-score = 0.7926169190537008\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: spectf_heart\n",
      "Dataset size: 267\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8450704225352113, Test accuracy = 0.6851851851851852\n",
      "knn, Train f1-score = 0.8469304922531746, Test f1-score = 0.6901771336553945\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.7222222222222222\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.7172048896186828\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(0.1), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.8591549295774648, Test accuracy = 0.7962962962962963\n",
      "log_reg, Train f1-score = 0.8446069676485882, Test f1-score = 0.7926169190537008\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.9859154929577465, Test accuracy = 0.7777777777777778\n",
      "random_forest, Train f1-score = 0.9857288981430413, Test f1-score = 0.6967592592592593\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(0.001)}\n",
      "gnb, Train accuracy = 0.7464788732394366, Test accuracy = 0.6111111111111112\n",
      "gnb, Train f1-score = 0.7705139930492044, Test f1-score = 0.6460785503377422\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7934272300469484, Test accuracy = 0.7962962962962963\n",
      "kmeans, Train f1-score = 0.7020377061671951, Test f1-score = 0.7059946544482627\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.8238850889192888 with params {'metric': 'euclidean', 'linkage': 'single', 'pca': False}\n",
      "agglo, Train accuracy = 0.7705882352941177, Test accuracy = 0.7777777777777778\n",
      "agglo, Train f1-score = 0.6758647645104554, Test f1-score = 0.6967592592592593\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7934272300469484, Test accuracy = 0.7962962962962963\n",
      "affinity_propagation, Train f1-score = 0.7020377061671951, Test f1-score = 0.7059946544482627\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: statlog\n",
      "Dataset size: 1000\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.80375, Test accuracy = 0.74\n",
      "knn, Train f1-score = 0.7825299274492775, Test f1-score = 0.7226666666666667\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.84125, Test accuracy = 0.755\n",
      "svm, Train f1-score = 0.8334851645310971, Test f1-score = 0.7455519760135243\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.78125, Test accuracy = 0.765\n",
      "log_reg, Train f1-score = 0.7705504235664722, Test f1-score = 0.7591321425231459\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 0.775\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 0.7628714327743453\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.75125, Test accuracy = 0.745\n",
      "gnb, Train f1-score = 0.7250513496199137, Test f1-score = 0.7332687651331719\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.7, Test accuracy = 0.7\n",
      "kmeans, Train f1-score = 0.5764705882352941, Test f1-score = 0.5764705882352941\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.7484375 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': True}\n",
      "agglo, Train accuracy = 0.6921875, Test accuracy = 0.695\n",
      "agglo, Train f1-score = 0.5688336795937211, Test f1-score = 0.5740412979351033\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.75625, Test accuracy = 0.72\n",
      "affinity_propagation, Train f1-score = 0.740269842491353, Test f1-score = 0.7013333333333334\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: wine_quality\n",
      "Dataset size: 6497\n",
      "Labels in dataset: [3 4 5 6 7 8 9]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.6676923076923077\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.657836173814751\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9948046950163556, Test accuracy = 0.6530769230769231\n",
      "svm, Train f1-score = 0.9948045853823578, Test f1-score = 0.6444920908821716\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(10.0), 'log_reg__max_iter': 1000, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 0.5464691167981528, Test accuracy = 0.5346153846153846\n",
      "log_reg, Train f1-score = 0.5123215422544114, Test f1-score = 0.5063778072895734\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 15, 'random_forest__n_estimators': 500}\n",
      "random_forest, Train accuracy = 0.9926880892822783, Test accuracy = 0.69\n",
      "random_forest, Train f1-score = 0.9926774951506017, Test f1-score = 0.6777249247356416\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 0.5074081200692707, Test accuracy = 0.4815384615384615\n",
      "gnb, Train f1-score = 0.4792111533067338, Test f1-score = 0.45212661340456056\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 7\n",
      "Cross validation best parameters:  {'n_clusters': 7, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.46719261112180105, Test accuracy = 0.4584615384615385\n",
      "kmeans, Train f1-score = 0.37955171745451655, Test f1-score = 0.36591009080737114\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.42352565644603174 with params {'metric': 'l1', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.4445513591532355, Test accuracy = 0.43538461538461537\n",
      "agglo, Train f1-score = 0.2796088179500807, Test f1-score = 0.26930084101782215\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.5482008851260343, Test accuracy = 0.5046153846153846\n",
      "affinity_propagation, Train f1-score = 0.5171987371807452, Test f1-score = 0.4748976115318229\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: zoo\n",
      "Dataset size: 101\n",
      "Labels in dataset: [1 2 3 4 5 6 7]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__C': np.float64(1.0), 'log_reg__max_iter': 100, 'log_reg__penalty': 'l2'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: random_forest\n",
      "Cross validation best parameters: {'random_forest__max_depth': 5, 'random_forest__n_estimators': 100}\n",
      "random_forest, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "random_forest, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: gnb\n",
      "Cross validation best parameters: {'gnb__var_smoothing': np.float64(1.0)}\n",
      "gnb, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "gnb, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 7\n",
      "Cross validation best parameters:  {'n_clusters': 7, 'algorithm': 'lloyd'}\n",
      "kmeans, Train accuracy = 0.8375, Test accuracy = 0.8095238095238095\n",
      "kmeans, Train f1-score = 0.7753205128205128, Test f1-score = 0.7420634920634921\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: agglomerative_clustering\n",
      "Best score 0.878125 with params {'metric': 'euclidean', 'linkage': 'average', 'pca': False}\n",
      "agglo, Train accuracy = 0.890625, Test accuracy = 1.0\n",
      "agglo, Train f1-score = 0.8721643518518518, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'preference': -50, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.875, Test accuracy = 0.9523809523809523\n",
      "affinity_propagation, Train f1-score = 0.8576286546553027, Test f1-score = 0.9365079365079364\n"
     ]
    }
   ],
   "source": [
    "for i, (name, id) in enumerate(data_set_sorted.items()):\n",
    "        print(\"\\n\" + \"*\"*100)\n",
    "        print(f\"Current dataset: {name}\")\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "        # Set up dataset\n",
    "        X, y = import_dataset(dataset_id[name], ordinal_encoder)\n",
    "        labels = np.unique(y)\n",
    "        y = encode_categorical_features(y, ordinal_encoder)\n",
    "        print(f\"Dataset size: {len(X)}\")\n",
    "        print(f\"Labels in dataset: {labels}\")\n",
    "\n",
    "        # split the dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify = y)\n",
    "        print(\"*\"*100, end=\"\\n\\n\")\n",
    "\n",
    "        # KNN\n",
    "        clf_name = \"knn\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        # https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "        knn = KNeighborsClassifier()\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(knn, clf_name, knn_params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # SVM \n",
    "        svm = SVC()\n",
    "        clf_name = \"svm\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(svm, clf_name, svm_params, X_train, y_train, X_test, y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Logistic regression\n",
    "        log_reg = LogisticRegression()\n",
    "        clf_name = \"log_reg\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(log_reg, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    log_reg_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # Random forest\n",
    "        random_forest = RandomForestClassifier()\n",
    "        clf_name = \"random_forest\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(random_forest, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    random_forest_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "        # Gaussian naive bayes\n",
    "        gnb = GaussianNB()\n",
    "        clf_name = \"gnb\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(gnb, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    gnb_params, \n",
    "                                                                                    X_train, \n",
    "                                                                                    y_train, \n",
    "                                                                                    X_test, \n",
    "                                                                                    y_test)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "       \n",
    "        # K-means\n",
    "        clf_name = \"kmeans\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        kmeans_params = [{\"algorithm\": [\"lloyd\", \"elkan\"]}]\n",
    "        n_clusters = len(labels)\n",
    "        kmeans_params.append({\"n_clusters\": [n_clusters]})\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = clustering_classification(KMeans, clf_name, kmeans_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1] )\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Agglomerative clustering\n",
    "        clf_name = \"agglomerative_clustering\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = agg_clustering(X_train, y_train, X_test, y_test, RANDOM_SEED)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "        \n",
    "\n",
    "        # Affinity propagation\n",
    "        clf_name = \"affinity_propagation\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test =  clustering_classification(AffinityPropagation, clf_name, affinity_propagation_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, name, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, name, clf_name, cm_test, \"test\", id[1])\n",
    "        metrics_dict = save_metrics_to_dict(clf_name,\n",
    "                                            train_acc, \n",
    "                                            train_f1, \n",
    "                                            test_acc, \n",
    "                                            test_f1, \n",
    "                                            metrics_dict,\n",
    "                                            i\n",
    "                                            )\n",
    "\n",
    "        # Write metrics to tensorboard, step is dataset id\n",
    "        writer.add_scalars(\"Train accuracy\", metrics_dict[\"train_acc_dict\"], id[1])\n",
    "        writer.add_scalars(\"Test accuracy\", metrics_dict[\"test_acc_dict\"], id[1])\n",
    "        writer.add_scalars(\"Train f1\",  metrics_dict[\"train_f1_dict\"], id[1])\n",
    "        writer.add_scalars(\"Test f1\", metrics_dict[\"test_f1_dict\"], id[1])\n",
    "        writer.add_scalars(\"Train average accuracy\", metrics_dict[\"train_acc_avg\"], id[1])\n",
    "        writer.add_scalars(\"Test average accuracy\", metrics_dict[\"test_acc_avg\"], id[1])\n",
    "        writer.add_scalars(\"Train average f1\", metrics_dict[\"train_f1_avg\"], id[1])\n",
    "        writer.add_scalars(\"Test average f1\", metrics_dict[\"test_f1_avg\"], id[1])\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank  Classifier                     Avg. test acc.    Avg. train acc.   Avg. test F1      Avg train F1     \n",
      "____________________________________________________________________________________________________\n",
      "1     random_forest                  0.87              0.99              0.86              0.99             \n",
      "2     svm                            0.86              0.97              0.85              0.97             \n",
      "3     knn                            0.85              0.96              0.85              0.96             \n",
      "4     log_reg                        0.84              0.84              0.83              0.83             \n",
      "5     gnb                            0.80              0.82              0.80              0.81             \n",
      "6     affinity_propagation           0.79              0.77              0.77              0.75             \n",
      "7     agglomerative_clustering       0.79              0.74              0.73              0.67             \n",
      "8     kmeans                         0.70              0.72              0.62              0.64             \n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Rank':<5} {'Classifier':<30} {'Avg. test acc.':<17} {'Avg. train acc.':<17} {'Avg. test F1':<17} {'Avg train F1':<17}\")\n",
    "print(\"_\"*100)\n",
    "for i, clf in enumerate(sorted(metrics_dict[\"test_acc_avg\"].items(), key=lambda x: x[1], reverse=True)):\n",
    "    print(f\"{i+1:<5} {clf[0][:-4]:<30} {clf[1]:<17.2f} {metrics_dict['train_acc_avg'][clf[0]]:<8.2f}\\\n",
    "          {metrics_dict['test_f1_avg'][clf[0]]:<18.2f}{metrics_dict['train_f1_avg'][clf[0]]:<17.2}\")\n",
    "print(\"_\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedAILabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
