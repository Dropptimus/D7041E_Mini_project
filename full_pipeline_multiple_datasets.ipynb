{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans, AffinityPropagation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from clustering import clustering_classification, test_classifier, write, save_metrics_to_dict, encode_categorical_features, import_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "train_acc_dict = {}\n",
    "train_f1_dict = {}\n",
    "test_acc_dict = {}\n",
    "test_f1_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# Launch tensorboard\n",
    "# images=21 change this to how many datasets you use\n",
    "%tensorboard --logdir runs/ --port 6006 --samples_per_plugin images=21\n",
    "# If in use (Mac) use to find the process PID\n",
    "% lsof -i :6006\n",
    "# Kill the process with \n",
    "% kill -9 <PID>\n",
    "# Then launch using bash with first command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "K_FOLDS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our chosen datasets\n",
    "TODO\n",
    "We have chosen the datasets based on the following criteria:\n",
    "- datasets where we do not need to do any special preprocessing so that it is easy to do in only one pipeline\n",
    "- rather small datasets to ensure we do not need high computational power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abalone': (1, 1), 'acute_inflamations': (184, 2), 'balance_scale': (12, 3), 'balloons': (13, 4), 'breast_cancer_wisconsin_diagnostic': (17, 5), 'car_evaluation': (19, 6), 'congress_voting_records': (105, 7), 'credit_approval': (27, 8), 'ecoli': (39, 9), 'fertility': (244, 10), 'habermans_survival': (43, 11), 'hayes_roth': (44, 12), 'heart_disease': (45, 13), 'ilpd': (225, 14), 'iris': (53, 15), 'lenses': (58, 16), 'mammographic_mass': (161, 17), 'mushroom': (73, 18), 'statlog': (144, 19), 'wine_quality': (186, 20), 'zoo': (111, 21)}\n"
     ]
    }
   ],
   "source": [
    "# Dataset that seems useful\n",
    "dataset_id = {\n",
    "    \"iris\": 53, \n",
    "    \"heart_disease\": 45, \n",
    "    \"wine_quality\": 186, \n",
    "    \"breast_cancer_wisconsin_diagnostic\": 17, \n",
    "    \"car_evaluation\": 19, \n",
    "    \"abalone\": 1, \n",
    "    \"mushroom\": 73, \n",
    "    \"statlog\" : 144, \n",
    "    \"credit_approval\" : 27, \n",
    "    \"zoo\" : 111, \n",
    "    \"balance_scale\" : 12, \n",
    "    \"ilpd\" : 225, \n",
    "    \"acute_inflamations\" : 184, \n",
    "    \"ecoli\" : 39, \n",
    "    \"mammographic_mass\" : 161, \n",
    "    \"hayes_roth\" : 44, \n",
    "    \"habermans_survival\" : 43, \n",
    "    \"congress_voting_records\" : 105, \n",
    "    \"balloons\" : 13, \n",
    "    \"lenses\" : 58, \n",
    "    \"fertility\" : 244, \n",
    "}\n",
    "\n",
    "data_set_sorted = {}\n",
    "for i, name in enumerate(sorted(dataset_id.keys())):\n",
    "    data_set_sorted[name] = (dataset_id[name], i+1)\n",
    "\n",
    "print(data_set_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and preprocess datasets\n",
    "For the preprocessing we will do the following steps:\n",
    "1. Remove any missing values. In the article the following is written: \"Given that our classifiers are not oriented to data with missing features, the missing inputs are treated as zero, which should not bias the comparison results.\" We therefore also decided to just remove missing values and to more focus on the full pipeline instead of single datasets. Another way could have been interpolation.\n",
    "2. Encode categorical data into numerical data. This we have to do to use the classifiers later on.\n",
    "3. Remove certain columns if they are highly correlated to others.\n",
    "4. Split the data into a train and a test set. We will use a 80/20 split.\n",
    "5. Scale the data so that we have zero mean and standard deviation of one. This is done with the Standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinal_encoder = OrdinalEncoder()\n",
    "# X, y = import_dataset(dataset_id[\"iris\"], ordinal_encoder)\n",
    "# y = encode_categorical_features(y, ordinal_encoder)\n",
    "# # split the dataset\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing different classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "knn_params = [{'knn__n_neighbors': [3, 5, 7, 9],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "        'knn__leaf_size': [15, 20]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "svm_params = [{'svm__C': [0.1, 1, 10, 100, 1000],  \n",
    "        'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "        'svm__kernel': ['rbf']} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params taken from here: https://www.geeksforgeeks.org/how-to-optimize-logistic-regression-performance/\n",
    "log_reg_params = [\n",
    "    {'log_reg__penalty':['l1','l2','elasticnet','none'],\n",
    "    #'log_reg__C' : np.logspace(-4,4,10),\n",
    "    'log_reg__solver': ['lbfgs','newton-cg','liblinear','saga'],\n",
    "    #'log_reg__max_iter'  : [100,2500,5000]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_params = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity propagation unsupervised classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "affinity_propagation_params = [{\"damping\": [0.5, 0.7]}, \n",
    "          {\"convergence_iter\": [10, 15]},\n",
    "          #{\"preference\": [0.01]}\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: abalone\n",
      "Dataset size: 4177\n",
      "Labels in dataset: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 29]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.40077821011673154, Test accuracy = 0.24043062200956938\n",
      "knn, Train f1-score = 0.38253583148275055, Test f1-score = 0.22477344651495762\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.29242741694103563, Test accuracy = 0.284688995215311\n",
      "svm, Train f1-score = 0.2633804010808711, Test f1-score = 0.25209235439559435\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'lbfgs'}\n",
      "log_reg, Train accuracy = 0.27985633043998803, Test accuracy = 0.2751196172248804\n",
      "log_reg, Train f1-score = 0.25258312751881545, Test f1-score = 0.24847519308649163\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 28\n",
      "Cross validation best parameters:  {'n_clusters': 28}\n",
      "kmeans, Train accuracy = 0.2723735408560311, Test accuracy = 0.2799043062200957\n",
      "kmeans, Train f1-score = 0.2364741946423434, Test f1-score = 0.2380556661842794\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.28434600419036216, Test accuracy = 0.2631578947368421\n",
      "affinity_propagation, Train f1-score = 0.25667408268673936, Test f1-score = 0.2319518869594213\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: acute_inflamations\n",
      "Dataset size: 120\n",
      "Labels in dataset: ['no' 'yes']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.8333333333333334, Test accuracy = 0.7916666666666666\n",
      "kmeans, Train f1-score = 0.8237133237133237, Test f1-score = 0.7664835164835164\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balance_scale\n",
      "Dataset size: 625\n",
      "Labels in dataset: ['B' 'L' 'R']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.914, Test accuracy = 0.856\n",
      "knn, Train f1-score = 0.8883796442851474, Test f1-score = 0.8185340637730019\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.952\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.9548433879761313\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.886, Test accuracy = 0.84\n",
      "log_reg, Train f1-score = 0.8520325097472862, Test f1-score = 0.8053352152434722\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3}\n",
      "kmeans, Train accuracy = 0.668, Test accuracy = 0.608\n",
      "kmeans, Train f1-score = 0.63918407960199, Test f1-score = 0.5737293729372936\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.818, Test accuracy = 0.736\n",
      "affinity_propagation, Train f1-score = 0.7859349214411927, Test f1-score = 0.7020398860398861\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: balloons\n",
      "Dataset size: 16\n",
      "Labels in dataset: ['F' 'T']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.6666666666666666, Test accuracy = 1.0\n",
      "knn, Train f1-score = 0.6458333333333334, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.75, Test accuracy = 0.75\n",
      "log_reg, Train f1-score = 0.7517482517482518, Test f1-score = 0.7333333333333334\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.75, Test accuracy = 0.5\n",
      "kmeans, Train f1-score = 0.7517482517482518, Test f1-score = 0.5\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 15, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.75, Test accuracy = 0.25\n",
      "affinity_propagation, Train f1-score = 0.7444444444444445, Test f1-score = 0.2\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: breast_cancer_wisconsin_diagnostic\n",
      "Dataset size: 569\n",
      "Labels in dataset: ['B' 'M']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9802197802197802, Test accuracy = 0.9473684210526315\n",
      "knn, Train f1-score = 0.9801024331803986, Test f1-score = 0.9473684210526315\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.0001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9824175824175824, Test accuracy = 0.9736842105263158\n",
      "svm, Train f1-score = 0.9823958851833416, Test f1-score = 0.973621425014614\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.989010989010989, Test accuracy = 0.9736842105263158\n",
      "log_reg, Train f1-score = 0.9890042738552068, Test f1-score = 0.9737421322933159\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.8967032967032967, Test accuracy = 0.9298245614035088\n",
      "kmeans, Train f1-score = 0.8957851037851037, Test f1-score = 0.928615457562826\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9516483516483516, Test accuracy = 0.9122807017543859\n",
      "affinity_propagation, Train f1-score = 0.9513266760060826, Test f1-score = 0.9118455861876914\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: car_evaluation\n",
      "Dataset size: 1728\n",
      "Labels in dataset: ['acc' 'good' 'unacc' 'vgood']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 20, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.9876989869753979, Test accuracy = 0.9421965317919075\n",
      "knn, Train f1-score = 0.9875204152120248, Test f1-score = 0.9397028688860987\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.9971098265895953\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.9970746892971808\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.7040520984081042, Test accuracy = 0.6734104046242775\n",
      "log_reg, Train f1-score = 0.6479957587827304, Test f1-score = 0.6068647117111459\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 4\n",
      "Cross validation best parameters:  {'n_clusters': 4}\n",
      "kmeans, Train accuracy = 0.7054992764109985, Test accuracy = 0.6791907514450867\n",
      "kmeans, Train f1-score = 0.5836756847693878, Test f1-score = 0.5494314168316536\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7945007235890015, Test accuracy = 0.7369942196531792\n",
      "affinity_propagation, Train f1-score = 0.7826345873089707, Test f1-score = 0.725960338075378\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: congress_voting_records\n",
      "Dataset size: 232\n",
      "Labels in dataset: ['democrat' 'republican']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.918918918918919, Test accuracy = 0.9787234042553191\n",
      "knn, Train f1-score = 0.9190898108084373, Test f1-score = 0.9787234042553191\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 0.8936170212765957\n",
      "svm, Train f1-score = 1.0, Test f1-score = 0.8926468162722784\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'saga'}\n",
      "log_reg, Train accuracy = 0.9945945945945946, Test accuracy = 0.9361702127659575\n",
      "log_reg, Train f1-score = 0.9945971406361762, Test f1-score = 0.9359965262700825\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.8810810810810811, Test accuracy = 0.9361702127659575\n",
      "kmeans, Train f1-score = 0.881289710763395, Test f1-score = 0.9361123172673325\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.9081081081081082, Test accuracy = 0.9787234042553191\n",
      "affinity_propagation, Train f1-score = 0.9083017855828956, Test f1-score = 0.9787234042553191\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: credit_approval\n",
      "Dataset size: 653\n",
      "Labels in dataset: ['+' '-']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8869731800766284, Test accuracy = 0.8473282442748091\n",
      "knn, Train f1-score = 0.8867382336517813, Test f1-score = 0.8473282442748091\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8908045977011494, Test accuracy = 0.8320610687022901\n",
      "svm, Train f1-score = 0.8909164375753115, Test f1-score = 0.8331451815217001\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'saga'}\n",
      "log_reg, Train accuracy = 0.8946360153256705, Test accuracy = 0.8396946564885496\n",
      "log_reg, Train f1-score = 0.8947811399836354, Test f1-score = 0.8406206761563434\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.553639846743295, Test accuracy = 0.5343511450381679\n",
      "kmeans, Train f1-score = 0.5209459694665131, Test f1-score = 0.499833528977303\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.8639846743295019, Test accuracy = 0.8015267175572519\n",
      "affinity_propagation, Train f1-score = 0.864143979700969, Test f1-score = 0.8027414787021464\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ecoli\n",
      "Dataset size: 336\n",
      "Labels in dataset: ['cp' 'im' 'imL' 'imS' 'imU' 'om' 'omL' 'pp']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8917910447761194, Test accuracy = 0.8823529411764706\n",
      "knn, Train f1-score = 0.8865770628196644, Test f1-score = 0.8752492313071769\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9216417910447762, Test accuracy = 0.8676470588235294\n",
      "svm, Train f1-score = 0.9199725560798104, Test f1-score = 0.8661939083933969\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.8917910447761194, Test accuracy = 0.8823529411764706\n",
      "log_reg, Train f1-score = 0.8879208972441605, Test f1-score = 0.8730465320456541\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 8\n",
      "Cross validation best parameters:  {'n_clusters': 8}\n",
      "kmeans, Train accuracy = 0.8171641791044776, Test accuracy = 0.7941176470588235\n",
      "kmeans, Train f1-score = 0.8117330589299397, Test f1-score = 0.7844678541272969\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.8582089552238806, Test accuracy = 0.8382352941176471\n",
      "affinity_propagation, Train f1-score = 0.8591941609321385, Test f1-score = 0.8322113872286883\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: fertility\n",
      "Dataset size: 100\n",
      "Labels in dataset: ['N' 'O']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "knn, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "svm, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'lbfgs'}\n",
      "log_reg, Train accuracy = 0.9, Test accuracy = 0.9\n",
      "log_reg, Train f1-score = 0.8693693693693693, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "kmeans, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.875, Test accuracy = 0.9\n",
      "affinity_propagation, Train f1-score = 0.8166666666666667, Test f1-score = 0.8526315789473683\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: habermans_survival\n",
      "Dataset size: 306\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.7663934426229508, Test accuracy = 0.6774193548387096\n",
      "knn, Train f1-score = 0.7401360335450284, Test f1-score = 0.6318428115663139\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 10, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.7950819672131147, Test accuracy = 0.6774193548387096\n",
      "svm, Train f1-score = 0.7660136648019755, Test f1-score = 0.6447772657450075\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.7663934426229508, Test accuracy = 0.6935483870967742\n",
      "log_reg, Train f1-score = 0.7144170996630014, Test f1-score = 0.6431541218637993\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.7418032786885246, Test accuracy = 0.7096774193548387\n",
      "kmeans, Train f1-score = 0.6318418514946963, Test f1-score = 0.5891661594643944\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7827868852459017, Test accuracy = 0.5967741935483871\n",
      "affinity_propagation, Train f1-score = 0.7477071293078893, Test f1-score = 0.5482762443188116\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: hayes_roth\n",
      "Dataset size: 132\n",
      "Labels in dataset: [1. 2. 3.]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 5, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.9428571428571428, Test accuracy = 0.6666666666666666\n",
      "knn, Train f1-score = 0.9428571428571428, Test f1-score = 0.6737152866062096\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9428571428571428, Test accuracy = 0.7037037037037037\n",
      "svm, Train f1-score = 0.9425825825825825, Test f1-score = 0.7037037037037037\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'saga'}\n",
      "log_reg, Train accuracy = 0.6476190476190476, Test accuracy = 0.5555555555555556\n",
      "log_reg, Train f1-score = 0.6488663719900961, Test f1-score = 0.5629629629629629\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3}\n",
      "kmeans, Train accuracy = 0.49523809523809526, Test accuracy = 0.48148148148148145\n",
      "kmeans, Train f1-score = 0.4724886053351692, Test f1-score = 0.42600972012736726\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.45714285714285713, Test accuracy = 0.48148148148148145\n",
      "affinity_propagation, Train f1-score = 0.4001285529082372, Test f1-score = 0.4251207729468599\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: heart_disease\n",
      "Dataset size: 297\n",
      "Labels in dataset: [0 1 2 3 4]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.6329113924050633, Test accuracy = 0.65\n",
      "knn, Train f1-score = 0.5863356600282779, Test f1-score = 0.5882456140350877\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.0001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.6919831223628692, Test accuracy = 0.6166666666666667\n",
      "svm, Train f1-score = 0.6640987589109606, Test f1-score = 0.5518518518518519\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.6708860759493671, Test accuracy = 0.6333333333333333\n",
      "log_reg, Train f1-score = 0.6384691534507607, Test f1-score = 0.5832010582010583\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 5\n",
      "Cross validation best parameters:  {'n_clusters': 5}\n",
      "kmeans, Train accuracy = 0.6033755274261603, Test accuracy = 0.6666666666666666\n",
      "kmeans, Train f1-score = 0.5280247031079809, Test f1-score = 0.6052790346907994\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.6244725738396625, Test accuracy = 0.5666666666666667\n",
      "affinity_propagation, Train f1-score = 0.5865991093167638, Test f1-score = 0.4995934959349594\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: ilpd\n",
      "Dataset size: 579\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.5775862068965517\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.5420125079929506\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.7365010799136069, Test accuracy = 0.6293103448275862\n",
      "svm, Train f1-score = 0.6247434533595521, Test f1-score = 0.4861339171683999\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.7494600431965442, Test accuracy = 0.6551724137931034\n",
      "log_reg, Train f1-score = 0.68366131904473, Test f1-score = 0.5542853573213393\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.7365010799136069, Test accuracy = 0.6293103448275862\n",
      "kmeans, Train f1-score = 0.6247434533595521, Test f1-score = 0.4861339171683999\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.7429805615550756, Test accuracy = 0.6379310344827587\n",
      "affinity_propagation, Train f1-score = 0.6659664521864678, Test f1-score = 0.5194418919572472\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: iris\n",
      "Dataset size: 150\n",
      "Labels in dataset: ['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 100, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.9666666666666667, Test accuracy = 0.9666666666666667\n",
      "svm, Train f1-score = 0.966624973942047, Test f1-score = 0.9664109121909632\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'lbfgs'}\n",
      "log_reg, Train accuracy = 0.9666666666666667, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.9666666666666666, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3}\n",
      "kmeans, Train accuracy = 0.8166666666666667, Test accuracy = 0.9333333333333333\n",
      "kmeans, Train f1-score = 0.8171841536871277, Test f1-score = 0.9319444444444444\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.95, Test accuracy = 0.9666666666666667\n",
      "affinity_propagation, Train f1-score = 0.949937343358396, Test f1-score = 0.966750208855472\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: lenses\n",
      "Dataset size: 24\n",
      "Labels in dataset: [1 2 3]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 0.8947368421052632, Test accuracy = 1.0\n",
      "knn, Train f1-score = 0.8918660287081339, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1, 'svm__gamma': 1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8947368421052632, Test accuracy = 1.0\n",
      "svm, Train f1-score = 0.8918660287081339, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'lbfgs'}\n",
      "log_reg, Train accuracy = 0.8947368421052632, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 0.8918660287081339, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 3\n",
      "Cross validation best parameters:  {'n_clusters': 3}\n",
      "kmeans, Train accuracy = 0.6842105263157895, Test accuracy = 1.0\n",
      "kmeans, Train f1-score = 0.7100226643162931, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8947368421052632, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 0.8918660287081339, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mammographic_mass\n",
      "Dataset size: 830\n",
      "Labels in dataset: [0 1]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 0.8283132530120482, Test accuracy = 0.8192771084337349\n",
      "knn, Train f1-score = 0.8282009579013729, Test f1-score = 0.8194874653568442\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.01, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.8509036144578314, Test accuracy = 0.8313253012048193\n",
      "svm, Train f1-score = 0.8504509397284112, Test f1-score = 0.8303314894576096\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 0.8283132530120482, Test accuracy = 0.8433734939759037\n",
      "log_reg, Train f1-score = 0.8283210428625454, Test f1-score = 0.8435783833006445\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.7936746987951807, Test accuracy = 0.8132530120481928\n",
      "kmeans, Train f1-score = 0.7925632930975004, Test f1-score = 0.8123500655473896\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.5}\n",
      "affinity_propagation, Train accuracy = 0.8237951807228916, Test accuracy = 0.8012048192771084\n",
      "affinity_propagation, Train f1-score = 0.8237899832590406, Test f1-score = 0.8014577669386239\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: mushroom\n",
      "Dataset size: 5644\n",
      "Labels in dataset: ['e' 'p']\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 3, 'knn__weights': 'uniform'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "knn, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 0.1, 'svm__gamma': 0.1, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "svm, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l1', 'log_reg__solver': 'liblinear'}\n",
      "log_reg, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "log_reg, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.8513842746400886, Test accuracy = 0.8449955713020372\n",
      "kmeans, Train f1-score = 0.8415266164967107, Test f1-score = 0.8333997192060056\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 1.0, Test accuracy = 1.0\n",
      "affinity_propagation, Train f1-score = 1.0, Test f1-score = 1.0\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: statlog\n",
      "Dataset size: 1000\n",
      "Labels in dataset: [1 2]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 7, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.77\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.7389290475485114\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n",
      "Cross validation best parameters: {'svm__C': 1000, 'svm__gamma': 0.001, 'svm__kernel': 'rbf'}\n",
      "svm, Train accuracy = 0.84, Test accuracy = 0.775\n",
      "svm, Train f1-score = 0.8349927302163644, Test f1-score = 0.764298323036187\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: log_reg\n",
      "Cross validation best parameters: {'log_reg__penalty': 'l2', 'log_reg__solver': 'newton-cg'}\n",
      "log_reg, Train accuracy = 0.77375, Test accuracy = 0.78\n",
      "log_reg, Train f1-score = 0.761882542829546, Test f1-score = 0.768651138307672\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: kmeans\n",
      "k-means n cluster 2\n",
      "Cross validation best parameters:  {'n_clusters': 2}\n",
      "kmeans, Train accuracy = 0.69875, Test accuracy = 0.705\n",
      "kmeans, Train f1-score = 0.574836276674025, Test f1-score = 0.5830205278592375\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: affinity_propagation\n",
      "Cross validation best parameters:  {'convergence_iter': 10, 'damping': 0.7}\n",
      "affinity_propagation, Train accuracy = 0.75875, Test accuracy = 0.725\n",
      "affinity_propagation, Train f1-score = 0.7348678911564626, Test f1-score = 0.6962178598100928\n",
      "\n",
      "****************************************************************************************************\n",
      "Current dataset: wine_quality\n",
      "Dataset size: 6497\n",
      "Labels in dataset: [3 4 5 6 7 8 9]\n",
      "****************************************************************************************************\n",
      "\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: knn\n",
      "Cross validation best parameters: {'knn__leaf_size': 15, 'knn__n_neighbors': 9, 'knn__weights': 'distance'}\n",
      "knn, Train accuracy = 1.0, Test accuracy = 0.6584615384615384\n",
      "knn, Train f1-score = 1.0, Test f1-score = 0.6499910171640016\n",
      "____________________________________________________________________________________________________\n",
      "Classifier: svm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m train_acc, train_f1, test_acc, test_f1, cm_train, cm_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43msvm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclf_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msvm_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m write(writer, clf_name, cm_train, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     45\u001b[0m write(writer, clf_name, cm_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mid\u001b[39m[\u001b[38;5;241m1\u001b[39m] )\n",
      "File \u001b[0;32m~/Desktop/D7041E Applied AI/D7041E_Mini_project/clustering.py:205\u001b[0m, in \u001b[0;36mtest_classifier\u001b[0;34m(clf, clf_name, params, X_train, y_train, X_test, y_test, display)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# Ravel to convert from (len, 1) shape to (len,), warning from sk-learn\u001b[39;00m\n\u001b[1;32m    204\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mravel(y_train)\n\u001b[0;32m--> 205\u001b[0m \u001b[43mgs_knn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross validation best parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gs_knn\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# find best model score\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/pipeline.py:473\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    472\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m routed_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 473\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LibSVM]\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[38;5;241m=\u001b[39m rnd\u001b[38;5;241m.\u001b[39mrandint(np\u001b[38;5;241m.\u001b[39miinfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_ \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/anaconda3/envs/D7041EMiniProject/lib/python3.11/site-packages/sklearn/svm/_base.py:328\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    314\u001b[0m libsvm\u001b[38;5;241m.\u001b[39mset_verbosity_wrap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    318\u001b[0m (\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_,\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport_vectors_,\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_support,\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdual_coef_,\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_,\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probA,\n\u001b[1;32m    325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_probB,\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_status_,\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_iter,\n\u001b[0;32m--> 328\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclass_weight_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mC\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprobability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprobability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshrinking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshrinking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name, id in data_set_sorted.items():\n",
    "        print(\"\\n\" + \"*\"*100)\n",
    "        print(f\"Current dataset: {name}\")\n",
    "        ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "        # Set up dataset\n",
    "        X, y = import_dataset(dataset_id[name], ordinal_encoder)\n",
    "        labels = np.unique(y)\n",
    "        y = encode_categorical_features(y, ordinal_encoder)\n",
    "        print(f\"Dataset size: {len(X)}\")\n",
    "        print(f\"Labels in dataset: {labels}\")\n",
    "\n",
    "        # split the dataset\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
    "        print(\"*\"*100, end=\"\\n\\n\")\n",
    "\n",
    "        # KNN\n",
    "        clf_name = \"knn\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        # https://towardsdatascience.com/gridsearchcv-for-beginners-db48a90114ee\n",
    "        knn = KNeighborsClassifier()\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(knn, clf_name, knn_params, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        write(writer, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, clf_name, cm_test, \"test\", id[1])\n",
    "\n",
    "        train_acc_dict, train_f1_dict, test_acc_dict, test_f1_dict = save_metrics_to_dict(clf_name, \n",
    "                                                                                          train_acc, \n",
    "                                                                                          train_f1, \n",
    "                                                                                          test_acc, \n",
    "                                                                                          test_f1, \n",
    "                                                                                          train_acc_dict, \n",
    "                                                                                          train_f1_dict, \n",
    "                                                                                          test_acc_dict, \n",
    "                                                                                          test_f1_dict)\n",
    "        \n",
    "        # SVM \n",
    "        svm = SVC()\n",
    "        clf_name = \"svm\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(svm, clf_name, svm_params, X_train, y_train, X_test, y_test)\n",
    "        write(writer, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, clf_name, cm_test, \"test\", id[1] )\n",
    "        train_acc_dict, train_f1_dict, test_acc_dict, test_f1_dict = save_metrics_to_dict(clf_name, \n",
    "                                                                                          train_acc, \n",
    "                                                                                          train_f1, \n",
    "                                                                                          test_acc, \n",
    "                                                                                          test_f1, \n",
    "                                                                                          train_acc_dict, \n",
    "                                                                                          train_f1_dict, \n",
    "                                                                                          test_acc_dict, \n",
    "                                                                                          test_f1_dict)\n",
    "\n",
    "        # Logistic regression\n",
    "        log_reg = LogisticRegression()\n",
    "        clf_name = \"log_reg\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = test_classifier(log_reg, \n",
    "                                                                                    clf_name, \n",
    "                                                                                    log_reg_params, X_train, y_train, X_test, y_test)\n",
    "        write(writer, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, clf_name, cm_test, \"test\", id[1] )\n",
    "        train_acc_dict, train_f1_dict, test_acc_dict, test_f1_dict = save_metrics_to_dict(clf_name, \n",
    "                                                                                          train_acc, \n",
    "                                                                                          train_f1, \n",
    "                                                                                          test_acc, \n",
    "                                                                                          test_f1, \n",
    "                                                                                          train_acc_dict, \n",
    "                                                                                          train_f1_dict, \n",
    "                                                                                          test_acc_dict, \n",
    "                                                                                          test_f1_dict)\n",
    "       \n",
    "        # K-means\n",
    "        clf_name = \"kmeans\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        kmeans_params = [{\"algorithm\": [\"lloyd\", \"elkan\"]}]\n",
    "        n_clusters = len(labels)\n",
    "        print(\"k-means n cluster\", n_clusters)\n",
    "        kmeans_params.append({\"n_clusters\": [n_clusters]})\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test = clustering_classification(KMeans, clf_name, kmeans_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, clf_name, cm_test, \"test\", id[1] )\n",
    "        train_acc_dict, train_f1_dict, test_acc_dict, test_f1_dict = save_metrics_to_dict(clf_name, \n",
    "                                                                                          train_acc, \n",
    "                                                                                          train_f1, \n",
    "                                                                                          test_acc, \n",
    "                                                                                          test_f1, \n",
    "                                                                                          train_acc_dict, \n",
    "                                                                                          train_f1_dict, \n",
    "                                                                                          test_acc_dict, \n",
    "                                                                                          test_f1_dict)\n",
    "\n",
    "        # Agglomerative clustering\n",
    "\n",
    "        \n",
    "\n",
    "        # Affinity propagation\n",
    "        clf_name = \"affinity_propagation\"\n",
    "        print(\"_\"*100)\n",
    "        print(f\"Classifier: {clf_name}\")\n",
    "        train_acc, train_f1, test_acc, test_f1, cm_train, cm_test =  clustering_classification(AffinityPropagation, clf_name, affinity_propagation_params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "        write(writer, clf_name, cm_train, \"train\", id[1])\n",
    "        write(writer, clf_name, cm_test, \"test\", id[1] )\n",
    "        train_acc_dict, train_f1_dict, test_acc_dict, test_f1_dict = save_metrics_to_dict(clf_name, \n",
    "                                                                                          train_acc, \n",
    "                                                                                          train_f1, \n",
    "                                                                                          test_acc, \n",
    "                                                                                          test_f1, \n",
    "                                                                                          train_acc_dict, \n",
    "                                                                                          train_f1_dict, \n",
    "                                                                                          test_acc_dict, \n",
    "                                                                                          test_f1_dict)\n",
    "\n",
    "        # Write metrics to tensorboard, step is dataset id\n",
    "        writer.add_scalars(\"Train acc\", train_acc_dict, id[1])\n",
    "        writer.add_scalars(\"Test acc\", test_acc_dict, id[1])\n",
    "        writer.add_scalars(\"Train f1\", train_f1_dict, id[1])\n",
    "        writer.add_scalars(\"Test f1\", test_f1_dict, id[1])\n",
    "\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm = SVC()\n",
    "# # params taken from here: https://www.geeksforgeeks.org/svm-hyperparameter-tuning-using-gridsearchcv-ml/\n",
    "# params = [{'svm__C': [0.1, 1, 10, 100, 1000],  \n",
    "#               'svm__gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "#               'svm__kernel': ['rbf']} ]\n",
    "\n",
    "# test_classifier(svm, \"svm\", params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_reg = LogisticRegression()\n",
    "# # params taken from here: https://www.geeksforgeeks.org/how-to-optimize-logistic-regression-performance/\n",
    "# params = [\n",
    "#     {'log_reg__penalty':['l1','l2','elasticnet','none'],\n",
    "#     #'log_reg__C' : np.logspace(-4,4,10),\n",
    "#     'log_reg__solver': ['lbfgs','newton-cg','liblinear','saga'],\n",
    "#     'log_reg__max_iter'  : [100,2500,5000]\n",
    "# }\n",
    "# ]\n",
    "\n",
    "# test_classifier(log_reg, \"log_reg\", params, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means clustering classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_clusters = len(np.unique(y_train))\n",
    "# params = [{\"n_clusters\": [n_clusters, int(n_clusters/2)]}]\n",
    "# clf_name = \"kmeans\"\n",
    "\n",
    "# train_acc, train_f1, test_acc, test_f1 = clustering_classification(KMeans, clf_name, params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "# train_acc_dict[clf_name] = train_acc\n",
    "# train_f1_dict[clf_name] = train_f1\n",
    "# test_acc_dict[clf_name] = test_acc\n",
    "# test_f1_dict[clf_name] = test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [{\"damping\": [0.5, 0.99]}, \n",
    "#           {\"convergence_iter\": [10, 15]},\n",
    "#           #{\"preference\": [0.01]}\n",
    "#           ]\n",
    "# clf_name = \"affinity_propagation\"\n",
    "\n",
    "# clustering_classification(AffinityPropagation, clf_name, params, X_train, y_train, X_test, y_test, RANDOM_SEED, K_FOLDS)\n",
    "# train_acc_dict[clf_name] = train_acc\n",
    "# train_f1_dict[clf_name] = train_f1\n",
    "# test_acc_dict[clf_name] = test_acc\n",
    "# test_f1_dict[clf_name] = test_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_acc_dict)\n",
    "# print(test_acc_dict)\n",
    "# print(train_f1_dict)\n",
    "# print(test_f1_dict)\n",
    "\n",
    "# writer.add_scalars(\"Train acc\", train_acc_dict)\n",
    "# writer.add_scalars(\"Test acc\", test_acc_dict)\n",
    "# writer.add_scalars(\"Train f1\", train_f1_dict)\n",
    "# writer.add_scalars(\"Test f1\", test_f1_dict)\n",
    "# writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AppliedAILabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
